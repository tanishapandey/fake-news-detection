{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Weibo_Final_Model_multiplicative.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52c40f9e67b44c6fad122dd35182f78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c578099f7a1b44f4816a04b44c80f2aa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0a4a6ac24b2d48f2ad097d2d77789c3f",
              "IPY_MODEL_870d9c66eba14f94b06c631d1c60672b"
            ]
          }
        },
        "c578099f7a1b44f4816a04b44c80f2aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a4a6ac24b2d48f2ad097d2d77789c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_835a62cd974348a9adbe10539356af24",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 109540,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109540,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1351062e3f2b4647884e4abeb073c95f"
          }
        },
        "870d9c66eba14f94b06c631d1c60672b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_68f57b6b57d9445f93fa7c4492450a05",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 110k/110k [00:00&lt;00:00, 191kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a92c6460ac5b41699a36665c71353d5b"
          }
        },
        "835a62cd974348a9adbe10539356af24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1351062e3f2b4647884e4abeb073c95f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68f57b6b57d9445f93fa7c4492450a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a92c6460ac5b41699a36665c71353d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f2ec43be50249ffb8a23b5e6f19f83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97167c73d6624c7cadae502a36113660",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f283a905da1b4bd88e510e79c83599f7",
              "IPY_MODEL_a1d4f5bd614a4fb5bbb2b15b27219a55"
            ]
          }
        },
        "97167c73d6624c7cadae502a36113660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f283a905da1b4bd88e510e79c83599f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_99375ca69ae4478facbd9993d624087d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 624,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 624,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b46e10dc90a3484a8fe953d320288299"
          }
        },
        "a1d4f5bd614a4fb5bbb2b15b27219a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_340807bd041f44c1b1413df1fc33164b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 624/624 [00:00&lt;00:00, 1.90kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5b5bf41fc094196b0a2ff669229e08f"
          }
        },
        "99375ca69ae4478facbd9993d624087d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b46e10dc90a3484a8fe953d320288299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "340807bd041f44c1b1413df1fc33164b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5b5bf41fc094196b0a2ff669229e08f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT57z3Kq6E7z",
        "outputId": "3a9b23f2-c5fa-4849-eb60-697e68deb307"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsa87LLn6aAw",
        "outputId": "a6e4b6ba-4517-440b-e16e-581f3bb75d78"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/40/866cbfac4601e0f74c7303d533a9c5d4a53858bd402e08e3e294dd271f25/transformers-4.2.1-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 37.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 35.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=8cce2b9802c7bbaa73cdd4fd09643055d40e1b08faeb73efd0d51ecb3cd30112\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soV3Z14B7CKz"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.nn import Parameter\n",
        "from transformers import BertModel\n",
        "from transformers import BertConfig\n",
        "from transformers import BertTokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import torch.optim as optim\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Do3_Jim-LqF"
      },
      "source": [
        "from transformers import BertLayer\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8sMHFHp7FcS"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE_-QaN0DX6X"
      },
      "source": [
        "def get_df(file):\n",
        "    return pd.read_csv(file, sep='|',header = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QECKknXvD9CD"
      },
      "source": [
        "train_df_fake = get_df('/content/drive/My Drive/WeiboRumorSet/WeiboRumorSet/tweets/train_rumor.txt')\n",
        "train_df_real = get_df('/content/drive/My Drive/WeiboRumorSet/WeiboRumorSet/tweets/train_nonrumor.txt')\n",
        "test_df_fake = get_df('/content/drive/My Drive/WeiboRumorSet/WeiboRumorSet/tweets/test_rumor.txt')\n",
        "test_df_real = get_df('/content/drive/My Drive/WeiboRumorSet/WeiboRumorSet/tweets/test_nonrumor.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "dRKcctPoLdF4",
        "outputId": "69c7d49c-560d-4620-df2b-6023310f12f3"
      },
      "source": [
        "train_df_fake"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3511947309647762</td>\n",
              "      <td>地球超级爆料</td>\n",
              "      <td>http://weibo.com/2803550292/z50NQEtP4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2012-11-13 16:55</td>\n",
              "      <td>true</td>\n",
              "      <td>79</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>2803550292</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5047.0</td>\n",
              "      <td>1770.0</td>\n",
              "      <td>1979.0</td>\n",
              "      <td>微博 weibo.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://ww1.sinaimg.cn/large/a71ac854gw1dytin2z...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>震惊，转发求证：【想都不敢想 ，在美国一桶金龙鱼食用油只要8元人民币】 一桶食用油相当于中国...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3576100079039606</td>\n",
              "      <td>Noodles_Liu</td>\n",
              "      <td>http://weibo.com/1000432103/zvVI3BVC6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2013-05-09 17:36</td>\n",
              "      <td>true</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1000432103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9049.0</td>\n",
              "      <td>490.0</td>\n",
              "      <td>28017.0</td>\n",
              "      <td>iPhone客户端</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://ww1.sinaimg.cn/large/3ba161e7jw1e4i6j4e...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11189</th>\n",
              "      <td>3795205020509978</td>\n",
              "      <td>雯雯兜兜2</td>\n",
              "      <td>http://weibo.com/5221338222/BDWIu28Fs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-01-04 07:30</td>\n",
              "      <td>true</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>11942</td>\n",
              "      <td>5221338222</td>\n",
              "      <td>0.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>622.0</td>\n",
              "      <td>iPhone 5s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11190</th>\n",
              "      <td>http://ww2.sinaimg.cn/large/a716fd45jw1enx4x69...</td>\n",
              "      <td>http://ww4.sinaimg.cn/large/a716fd45jw1enx4x6d...</td>\n",
              "      <td>http://ww3.sinaimg.cn/large/a716fd45jw1enx4x6k...</td>\n",
              "      <td>http://ww1.sinaimg.cn/large/a716fd45jw1enx4x6q...</td>\n",
              "      <td>http://ww4.sinaimg.cn/large/a716fd45jw1enx4x6r...</td>\n",
              "      <td>http://ww4.sinaimg.cn/large/a716fd45jw1enx4x70...</td>\n",
              "      <td>http://ww1.sinaimg.cn/large/a716fd45jw1enx4x71...</td>\n",
              "      <td>http://ww1.sinaimg.cn/large/a716fd45jw1enx4x75...</td>\n",
              "      <td>http://ww1.sinaimg.cn/large/a716fd45jw1enx4x7e...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11191</th>\n",
              "      <td>3720633525700857</td>\n",
              "      <td>D-雨中伞</td>\n",
              "      <td>http://weibo.com/3071526677/B8ELSnV3j</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-01-02 17:01</td>\n",
              "      <td>true</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>968</td>\n",
              "      <td>3071526677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>iPhone客户端</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11192</th>\n",
              "      <td>http://ww4.sinaimg.cn/large/668669eagw1ec59jtc...</td>\n",
              "      <td>http://ww3.sinaimg.cn/large/668669eagw1ec59k3d...</td>\n",
              "      <td>http://ww3.sinaimg.cn/large/668669eagw1ec59k4k...</td>\n",
              "      <td>http://ww3.sinaimg.cn/large/668669eagw1ec59k75...</td>\n",
              "      <td>http://ww4.sinaimg.cn/large/668669eagw1ec59k9w...</td>\n",
              "      <td>http://ww2.sinaimg.cn/large/668669eagw1ec59kdv...</td>\n",
              "      <td>http://ww4.sinaimg.cn/large/668669eagw1ec59kxd...</td>\n",
              "      <td>http://ww2.sinaimg.cn/large/668669eagw1ec59kzu...</td>\n",
              "      <td>http://ww1.sinaimg.cn/large/668669eagw1ec59l1t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11193</th>\n",
              "      <td>@朱秋霞77:寻人 13969597919帮忙扩散，今天上午一个三岁多小女孩在高新开发区怡馨...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11194 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      0   ...            14\n",
              "0                                       3511947309647762  ...  微博 weibo.com\n",
              "1      http://ww1.sinaimg.cn/large/a71ac854gw1dytin2z...  ...           NaN\n",
              "2      震惊，转发求证：【想都不敢想 ，在美国一桶金龙鱼食用油只要8元人民币】 一桶食用油相当于中国...  ...           NaN\n",
              "3                                       3576100079039606  ...     iPhone客户端\n",
              "4      http://ww1.sinaimg.cn/large/3ba161e7jw1e4i6j4e...  ...           NaN\n",
              "...                                                  ...  ...           ...\n",
              "11189                                   3795205020509978  ...     iPhone 5s\n",
              "11190  http://ww2.sinaimg.cn/large/a716fd45jw1enx4x69...  ...           NaN\n",
              "11191                                   3720633525700857  ...     iPhone客户端\n",
              "11192  http://ww4.sinaimg.cn/large/668669eagw1ec59jtc...  ...           NaN\n",
              "11193  @朱秋霞77:寻人 13969597919帮忙扩散，今天上午一个三岁多小女孩在高新开发区怡馨...  ...           NaN\n",
              "\n",
              "[11194 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeesQVhmEN-G"
      },
      "source": [
        "train_fake = train_df_fake[0].tolist()\n",
        "train_real = train_df_real[0].tolist()\n",
        "test_fake = test_df_fake[0].tolist()\n",
        "test_real = test_df_real[0].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXSZwwNFAPwZ"
      },
      "source": [
        "def fix_offset(list_):\n",
        "    fixed_flag = False\n",
        "\n",
        "    while not fixed_flag:\n",
        "        exit_flag=False\n",
        "        temp = copy.deepcopy(list_)\n",
        "        for i,v in enumerate(temp):\n",
        "            if v!=None:\n",
        "                if 'sinaimg.cn' in v:\n",
        "                    if list_[i+1] !=None:\n",
        "                        if list_[i+1].isdigit():\n",
        "                            list_.insert(i+1,None)\n",
        "                            exit_flag=True\n",
        "                            break\n",
        "        if not exit_flag:\n",
        "            fixed_flag=True\n",
        "            \n",
        "    return list_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVcK9wT4ASoB"
      },
      "source": [
        "train_fake = fix_offset(train_fake) \n",
        "train_real = fix_offset(train_real)\n",
        "test_fake = fix_offset(test_fake)\n",
        "test_real = fix_offset(test_real)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MNsZVuuAYBX"
      },
      "source": [
        "def break_in_block(list_):\n",
        "    temp = []\n",
        "    for i in range(0,len(list_),3):\n",
        "        temp.append(list_[i:i+3])\n",
        "    return temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adld7d9xAZKg"
      },
      "source": [
        "train_fake = break_in_block(train_fake)\n",
        "train_real = break_in_block(train_real)\n",
        "test_fake = break_in_block(test_fake)\n",
        "test_real = break_in_block(test_real)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btUd790YAeVS",
        "outputId": "b6b60650-b06b-45e9-9ca8-8b543e556ad0"
      },
      "source": [
        "len(train_fake),len(train_real),len(test_fake),len(test_real)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3748, 3783, 1000, 996)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv1ye6miMglo",
        "outputId": "7147d899-a9fb-43e6-abf5-6e0d7ffcbbe9"
      },
      "source": [
        "train_fake[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['3511947309647762',\n",
              " 'http://ww1.sinaimg.cn/large/a71ac854gw1dytin2zmk9j.jpg',\n",
              " '震惊，转发求证：【想都不敢想 ，在美国一桶金龙鱼食用油只要8元人民币】 一桶食用油相当于中国超市40多元(现在估计已经涨到五六十元了)的金龙鱼，在纽约沃尔玛感恩节时是1.6美元，圣诞节降至1.3美元。(折合人民币8.58元，而且油是绿色纯天然的，不是转基因的)，为什么中国一桶食用油要卖几十上百元？']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7xAnDugAiMw"
      },
      "source": [
        "def get_image_and_text_list(blocks_list):\n",
        "    image_list = []\n",
        "    text_list = []\n",
        "    for i in blocks_list:\n",
        "        if i[-1] !=None:\n",
        "            image_list.append(i[1])\n",
        "            text_list.append(i[-1])\n",
        "    image_list = [i.split('/')[-1] for i in image_list]\n",
        "    return image_list, text_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSqmQPhtAk30"
      },
      "source": [
        "train_fake_image,train_fake_text = get_image_and_text_list(train_fake)\n",
        "train_real_image,train_real_text = get_image_and_text_list(train_real)\n",
        "test_fake_image,test_fake_text = get_image_and_text_list(test_fake)\n",
        "test_real_image,test_real_text = get_image_and_text_list(test_real)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xTCSD2yAoCS"
      },
      "source": [
        "train_fake_Y = [0]*len(train_fake_image)\n",
        "train_real_Y = [1]*len(train_real_image)\n",
        "test_fake_Y = [0]*len(test_fake_image)\n",
        "test_real_Y = [1]*len(test_real_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMolhYaBAr2X"
      },
      "source": [
        "train_images = train_fake_image+train_real_image\n",
        "train_text = train_fake_text + train_real_text\n",
        "trainY = train_fake_Y+train_real_Y\n",
        "\n",
        "test_images = test_fake_image+test_real_image\n",
        "test_text = test_fake_text+test_real_text\n",
        "testY = test_fake_Y+test_real_Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWZ31XxGAvCh",
        "outputId": "40160806-ee76-461c-ad90-823b83c432de"
      },
      "source": [
        "len(train_images),len(train_text),len(trainY),len(test_images),len(test_text),len(testY)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7481, 7481, 7481, 1930, 1930, 1930)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUKFw8V9AzAc"
      },
      "source": [
        "train_images = np.array(train_images)\n",
        "train_text = np.array(train_text)\n",
        "trainY = np.array(trainY)\n",
        "test_images = np.array(test_images)\n",
        "test_text = np.array(test_text)\n",
        "testY = np.array(testY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbFEYcqFuYv6"
      },
      "source": [
        "from os import walk\n",
        "def get_total_images() :\n",
        "  mypath = \"/content/drive/My Drive/multi-modal/weibo/airsplay/feat_rumor/\"\n",
        "  mypath1 = \"/content/drive/My Drive/multi-modal/weibo/airsplay/feat_nonrumor/\"\n",
        "  img_feat = []\n",
        "  for (dirpath, dirnames, filenames) in walk(mypath):\n",
        "      img_feat.extend(filenames)\n",
        "      break\n",
        "  print(\"Read feat rumor\")\n",
        "  for (dirpath, dirnames, filenames) in walk(mypath1):\n",
        "      img_feat.extend(filenames)\n",
        "      break \n",
        "  print(\"Read feat nonrumor\")\n",
        "  mypath3 = \"/content/drive/My Drive/WeiboRumorSet/WeiboRumorSet/rumor_images/\"\n",
        "  images = []\n",
        "  for (dirpath, dirnames, filenames) in walk(mypath3):\n",
        "      images.extend(filenames)\n",
        "      break\n",
        "  print(\"Read feat rumor\")\n",
        "  mypath4 = \"/content/drive/My Drive/WeiboRumorSet/WeiboRumorSet/nonrumor_images/\"\n",
        "  for (dirpath, dirnames, filenames) in walk(mypath4):\n",
        "      images.extend(filenames)\n",
        "      break\n",
        "  print(\"Read feat non rumor\")\n",
        "  img_dict = {}\n",
        "  for img in images :\n",
        "    img_dict[img[:-4]] = img\n",
        "  total_img = []\n",
        "  for img in img_feat :\n",
        "    total_img.append(img_dict[img[:-4]])\n",
        "  return total_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB3MPIbTwwGr",
        "outputId": "6581bd4f-cfee-4fc1-ab2c-d5279a7e1190"
      },
      "source": [
        "total_images = get_total_images()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read feat rumor\n",
            "Read feat nonrumor\n",
            "Read feat rumor\n",
            "Read feat non rumor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXhrocIuA325"
      },
      "source": [
        "def index_to_delete(list_, total_images):\n",
        "    # list_images_dir = listdir('WeiboRumorSet/images/')\n",
        "    gif_list = ['957e1cf2tw1e5foxts295g206o03p4qp.gif','a716fd45jw1ev0cgf8j46g209505zh4i.gif','005vnhZYgw1evupo8ttddg308w06o4qp.gif','7da75521gw1ele2jvi85rg2096056u0x.gif']\n",
        "    index = []\n",
        "    for i,v in enumerate(list_):\n",
        "        if v not in total_images:\n",
        "            index.append(i)\n",
        "        # if v in gif_list:\n",
        "        #     index.append(i)\n",
        "    return index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKBr_zCQA6sR",
        "outputId": "6d5bae40-45f6-4ff2-85eb-a65a695e6d51"
      },
      "source": [
        "train_delete_index =index_to_delete(train_images, total_images)\n",
        "test_delete_index = index_to_delete(test_images, total_images)\n",
        "len(train_delete_index)+len(test_delete_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4147"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrrLkVhU1rUP"
      },
      "source": [
        "train_images = np.delete(train_images,train_delete_index)\n",
        "train_text = np.delete(train_text,train_delete_index)\n",
        "trainY = np.delete(trainY,train_delete_index)\n",
        "test_images = np.delete(test_images,test_delete_index)\n",
        "test_text = np.delete(test_text,test_delete_index)\n",
        "testY = np.delete(testY,test_delete_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ-nCMzMA9q_"
      },
      "source": [
        "shuffle_index= np.arange(len(train_images))\n",
        "np.random.shuffle(shuffle_index)\n",
        "train_images = train_images[shuffle_index]\n",
        "train_text = train_text[shuffle_index]\n",
        "trainY = trainY[shuffle_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D2Xp4G1CD2h",
        "outputId": "3ace8531-ebc0-4146-868b-213fb947fc1b"
      },
      "source": [
        "len(train_images),len(train_text),len(trainY),len(test_images),len(test_text),len(testY)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4140, 4140, 4140, 1124, 1124, 1124)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjHkb6c_u1lQ",
        "outputId": "5063f5c8-1370-42c8-900c-5c9998db8a78"
      },
      "source": [
        "print(train_images[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "691a88dejw1e3vzjeo5yqj208i0bk0u5.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLKO_gM42gMz",
        "outputId": "094f955b-f390-492a-d26a-e99733f09b27"
      },
      "source": [
        "dict_class = {}\n",
        "mypath = \"/content/drive/My Drive/multi-modal/weibo/airsplay/feat_rumor/\"\n",
        "mypath1 = \"/content/drive/My Drive/multi-modal/weibo/airsplay/feat_nonrumor/\"\n",
        "img_feat = []\n",
        "for (dirpath, dirnames, filenames) in walk(mypath):\n",
        "    img_feat.extend(filenames)\n",
        "    break\n",
        "for img in img_feat :\n",
        "  dict_class[img[:-4]] = \"rumor\"\n",
        "print(\"Read feat rumor\")\n",
        "img_feat1 = []\n",
        "for (dirpath, dirnames, filenames) in walk(mypath1):\n",
        "    img_feat1.extend(filenames)\n",
        "    break \n",
        "for img in img_feat1 :\n",
        "  dict_class[img[:-4]] = \"nonrumor\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read feat rumor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOItB7SNNfvO"
      },
      "source": [
        "dict_feat = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqsQmmxODbkG"
      },
      "source": [
        "for img in train_images :\n",
        "  key = img[:-4]\n",
        "  if (key not in dict_feat) :\n",
        "    if (dict_class[key]==\"rumor\") :\n",
        "      dict_feat[key] = pickle.load(open(\"/content/drive/My Drive/multi-modal/weibo/airsplay/feat_rumor/\"+key+\".pkl\",\"rb\"))\n",
        "    else :\n",
        "      dict_feat[key] = pickle.load(open(\"/content/drive/My Drive/multi-modal/weibo/airsplay/feat_nonrumor/\"+key+\".pkl\",\"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMVKKXC3uPSU"
      },
      "source": [
        "for img in test_images :\n",
        "  key = img[:-4]\n",
        "  if (key not in dict_feat) :\n",
        "    if (dict_class[key]==\"rumor\") :\n",
        "      dict_feat[key] = pickle.load(open(\"/content/drive/My Drive/multi-modal/weibo/airsplay/feat_rumor/\"+key+\".pkl\",\"rb\"))\n",
        "    else :\n",
        "      dict_feat[key] = pickle.load(open(\"/content/drive/My Drive/multi-modal/weibo/airsplay/feat_nonrumor/\"+key+\".pkl\",\"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBAmI0VaKKDQ",
        "outputId": "4b3a3a15-e8a7-4fc8-e390-f3641ae5c44c"
      },
      "source": [
        "len(list(dict_feat.keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5264"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nOXTCrxNgx_",
        "outputId": "88a3bbb3-9010-4dd9-b6c3-2422060b5a54"
      },
      "source": [
        "c=0\n",
        "shape_not_match = []\n",
        "for key in dict_feat :\n",
        "  if(dict_feat[key].shape[0]!=36) :\n",
        "    shape_not_match.append(key)\n",
        "    c+=1\n",
        "print(c)\n",
        "print(len(shape_not_match))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "675\n",
            "675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAV8oux0OcvB"
      },
      "source": [
        "# dict_feat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uqTN0eCNRJ_"
      },
      "source": [
        "def index_to_delete_shape(images, shape_not_match) :\n",
        "  index = []\n",
        "  for i in range(len(images)) :\n",
        "    main_image = images[i]\n",
        "    if ((main_image[:-4] in shape_not_match)) :\n",
        "      index.append(i)\n",
        "  return index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3Ha1kysNrwq",
        "outputId": "c6a2bc1c-8862-4376-beb0-5903465baa29"
      },
      "source": [
        "train_delete_index =index_to_delete_shape(train_images, shape_not_match)\n",
        "test_delete_index = index_to_delete_shape(test_images, shape_not_match)\n",
        "len(train_delete_index)+len(test_delete_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "675"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meUZEMgKN1hF"
      },
      "source": [
        "train_images1 = np.delete(train_images,train_delete_index)\n",
        "train_text1 = np.delete(train_text,train_delete_index)\n",
        "trainY1 = np.delete(trainY,train_delete_index)\n",
        "test_images1 = np.delete(test_images,test_delete_index)\n",
        "test_text1 = np.delete(test_text,test_delete_index)\n",
        "testY1 = np.delete(testY,test_delete_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNmM4FJq3XSN",
        "outputId": "83c087e1-af9d-42c3-c2b0-5a1abcbd5eed"
      },
      "source": [
        "len(train_images1),len(train_text1),len(trainY1),len(test_images1),len(test_text1),len(testY1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3617, 3617, 3617, 972, 972, 972)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CVPIWdp7AJ0",
        "outputId": "df0e9952-e07c-47f8-b437-9ba0bccfa004"
      },
      "source": [
        "# fin_train_img = []\n",
        "# c=0\n",
        "# ids_train = []\n",
        "# for i in range(len(train_images)) :\n",
        "#   main_image = train_images[i]\n",
        "#   if((main_image[:-4] not in shape_not_match)) :\n",
        "#     fin_train_img.append(main_image)\n",
        "#     ids_train.append(i)\n",
        "#     c+=1\n",
        "\n",
        "# print(c)\n",
        "# print(len(ids_train))\n",
        "# print(len(fin_train_img))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3617\n",
            "3617\n",
            "3617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dbxf3Q7bNr2p"
      },
      "source": [
        "# dict_feat_test = {}\n",
        "\n",
        "# for file_name in pickle_img_test :\n",
        "#   dict_feat_test[file_name[:-4]] =  pickle.load(open(\"/content/drive/My Drive/multi-modal/mediaeval/airsplay/feat_test/\"+file_name,\"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvCqSyqpN1rF",
        "outputId": "d0f090b4-1b48-41e5-8b4d-efbd31c06b59"
      },
      "source": [
        "# c=0\n",
        "# shape_not_match_test = []\n",
        "# for key in dict_feat_test :\n",
        "#   if(dict_feat_test[key].shape[0]!=36) :\n",
        "#     shape_not_match_test.append(key)\n",
        "#     c+=1\n",
        "# print(c)\n",
        "# print(len(shape_not_match_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPsmgR5aJplz",
        "outputId": "50ecd233-70b2-4b02-8410-141dbb735543"
      },
      "source": [
        "# fin_test_img = []\n",
        "# c=0\n",
        "# ids_test = []\n",
        "# for i in range(len(test_images)) :\n",
        "#   main_image = test_images[i]\n",
        "#   if (main_image[:-4] not in shape_not_match) :\n",
        "#     fin_test_img.append(main_image)\n",
        "#     ids_test.append(i)\n",
        "#     c+=1\n",
        "\n",
        "# print(c)\n",
        "# print(len(ids_test))\n",
        "# print(len(fin_test_img))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "972\n",
            "972\n",
            "972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccHkX0gn7sGT"
      },
      "source": [
        "train_input_img = torch.zeros((3617,36,2048))\n",
        "train_output_img = torch.zeros((3617,2))\n",
        "\n",
        "for i in range(len(train_images1)) :\n",
        "  main_image = train_images1[i]\n",
        "  train_input_img[i] = dict_feat[main_image[:-4]]\n",
        "  if (trainY1[i]==0) :\n",
        "    train_output_img[i][0] = 1\n",
        "  else :\n",
        "    train_output_img[i][1] = 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF-g7sSg1jF1",
        "outputId": "ce3295d0-9319-4c4b-a3fc-5bd6fb7bdc62"
      },
      "source": [
        "len(ids_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3617"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxlEkX5N8HkF"
      },
      "source": [
        "test_input_img = torch.zeros((972,36,2048))\n",
        "test_output_img = torch.zeros((972,2))\n",
        "\n",
        "for i in range(len(test_images1)) :\n",
        "  main_image = test_images1[i]\n",
        "  test_input_img[i] = dict_feat[main_image[:-4]]\n",
        "  if (testY1[i]==0) :\n",
        "    test_output_img[i][0] = 1\n",
        "  else :\n",
        "    test_output_img[i][1] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTj6eFRi8KcY",
        "outputId": "9e6b8e8c-0e51-45fb-f1fc-ac52d6b73368"
      },
      "source": [
        "print(len(train_input_img))\n",
        "print(len(train_output_img))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3617\n",
            "3617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YH9hZxp4oq7"
      },
      "source": [
        "def gelu(x):\n",
        "    \"\"\"Implementation of the gelu activation function.\n",
        "        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n",
        "        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "    \"\"\"\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "class BERTLayerNorm(nn.Module):\n",
        "    def __init__(self, config, variance_epsilon=1e-12):\n",
        "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
        "        \"\"\"\n",
        "        super(BERTLayerNorm, self).__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(config.hidden_size))\n",
        "        self.beta = nn.Parameter(torch.zeros(config.hidden_size))\n",
        "        self.variance_epsilon = variance_epsilon\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = x.mean(-1, keepdim=True)\n",
        "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "        return self.gamma * x + self.beta\n",
        "\n",
        "class BERTSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BERTSelfAttention, self).__init__()\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\n",
        "            raise ValueError(\n",
        "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
        "                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads))\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "        attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)\n",
        "        return context_layer\n",
        "\n",
        "\n",
        "class BERTSelfOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BERTSelfOutput, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.LayerNorm = BERTLayerNorm(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BERTAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BERTAttention, self).__init__()\n",
        "        self.self = BERTSelfAttention(config)\n",
        "        self.output = BERTSelfOutput(config)\n",
        "\n",
        "    def forward(self, input_tensor, attention_mask):\n",
        "        self_output = self.self(input_tensor, attention_mask)\n",
        "        attention_output = self.output(self_output, input_tensor)\n",
        "        return attention_output\n",
        "\n",
        "\n",
        "class BERTIntermediate(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BERTIntermediate, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "        self.intermediate_act_fn = gelu\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BERTOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BERTOutput, self).__init__()\n",
        "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "        self.LayerNorm = BERTLayerNorm(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BERTLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BERTLayer, self).__init__()\n",
        "        self.attention = BERTAttention(config)\n",
        "        self.intermediate = BERTIntermediate(config)\n",
        "        self.output = BERTOutput(config)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        attention_output = self.attention(hidden_states, attention_mask)\n",
        "        intermediate_output = self.intermediate(attention_output)\n",
        "        layer_output = self.output(intermediate_output, attention_output)\n",
        "        return layer_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8onzhCH36VSx"
      },
      "source": [
        "class TransformerMapping(nn.Module):\n",
        "    \"\"\" Self-attention layer for image branch\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(TransformerMapping, self).__init__()\n",
        "        bert_config = BertConfig.from_json_file(\"t_cfg.json\")\n",
        "        self.layer = BERTLayer(bert_config)\n",
        "        self.mapping = nn.Linear(2048, 256)\n",
        "        #self.mapping2 = nn.Linear(opt.final_dims, opt.final_dims)\n",
        "        self.cls_layer = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, patch_num, img_dim)\n",
        "        # print(\"x\", x.shape)\n",
        "        x = self.mapping(x) # x: (batch_size, patch_num, final_dims)\n",
        "        # print(\"x_mapping\", x.shape)\n",
        "        attention_mask = torch.ones(x.size(0), x.size(1))\n",
        "        if torch.cuda.is_available():\n",
        "            attention_mask = attention_mask.cuda()\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "        extended_attention_mask = extended_attention_mask.float()\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        hidden_states = self.layer(x, extended_attention_mask)\n",
        "        # print(\"hidden_states\",hidden_states.shape)\n",
        "        # hidden_states = self.mapping2(hidden_states)\n",
        "        embed = torch.mean(hidden_states, 1) # (batch_size, final_dims)\n",
        "        codes = F.normalize(embed, p=2, dim=1)  # (N, C)\n",
        "        codes = self.cls_layer(codes)\n",
        "        codes = F.softmax(codes, dim=1)\n",
        "        return codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxC7f6ILgjdz"
      },
      "source": [
        "## Text embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ickNx4HjgnPr"
      },
      "source": [
        "def freeze_layers(model):\n",
        "    for child in model.children():\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMN-zGd8hIN-"
      },
      "source": [
        "class BertMapping(nn.Module):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(BertMapping, self).__init__()\n",
        "        # bert_config = BertConfig.from_json_file(opt.bert_config_file)\n",
        "        bert_config = BertConfig.from_pretrained('bert-base-chinese')\n",
        "        self.bert = BertModel(bert_config)\n",
        "        # self.bert.load_state_dict(torch.load(opt.init_checkpoint, map_location='cpu'))\n",
        "        freeze_layers(self.bert)\n",
        "        final_dims = 256\n",
        "        Ks = [1, 2, 3]\n",
        "        in_channel = 1\n",
        "        out_channel = 512\n",
        "        embedding_dim = bert_config.hidden_size\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(in_channel, out_channel, (K, embedding_dim)) for K in Ks])\n",
        "        self.dropout = nn.Dropout(bert_config.hidden_dropout_prob)\n",
        "        self.mapping = nn.Linear(len(Ks)*out_channel, final_dims)\n",
        "        self.cls_layer = nn.Linear(final_dims, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids,attention_mask=attention_mask, return_dict=True)\n",
        "        x = outputs.last_hidden_state.unsqueeze(1)  # (batch_size, 1, token_num, embedding_dim)\n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(batch_size, out_channel, W), ...]*len(Ks)\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
        "        output = torch.cat(x, 1)\n",
        "\n",
        "        output = self.dropout(output)\n",
        "        code = self.mapping(output)\n",
        "        # code = F.tanh(code)\n",
        "        code = F.normalize(code, p=2, dim=1)\n",
        "        code = self.cls_layer(code)\n",
        "        code = F.softmax(code, dim=1)\n",
        "        return code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP9CsiAf6JeO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "52c40f9e67b44c6fad122dd35182f78f",
            "c578099f7a1b44f4816a04b44c80f2aa",
            "0a4a6ac24b2d48f2ad097d2d77789c3f",
            "870d9c66eba14f94b06c631d1c60672b",
            "835a62cd974348a9adbe10539356af24",
            "1351062e3f2b4647884e4abeb073c95f",
            "68f57b6b57d9445f93fa7c4492450a05",
            "a92c6460ac5b41699a36665c71353d5b"
          ]
        },
        "id": "FYqh0-vMIJbl",
        "outputId": "bd80f141-2ba6-4d85-b5f1-cc79b6de583a"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52c40f9e67b44c6fad122dd35182f78f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVYlnuFZIi68"
      },
      "source": [
        "def get_token_ids(x_train, x_test):\n",
        "    \n",
        "    token_tr = []\n",
        "    token_tst = []\n",
        "    count = 0\n",
        "    for sent in x_train :\n",
        "        tokens = tokenizer.encode(sent, add_special_tokens = True, max_length=512)\n",
        "        token_tr.append(tokens)\n",
        "        count+=1\n",
        "        if(count%1000==0):\n",
        "            print(count)\n",
        "    \n",
        "    for sent1 in x_test :\n",
        "        tokens1 = tokenizer.encode(sent1, add_special_tokens = True, max_length=512)\n",
        "        token_tst.append(tokens1)\n",
        "        count+=1\n",
        "        if(count%1000==0):\n",
        "            print(count)\n",
        "            \n",
        "    return token_tr, token_tst "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUSgvPHsIYly",
        "outputId": "545f76c0-39aa-4b2a-dd78-73fd8e75e7cb"
      },
      "source": [
        "xtr_token, xtst_token = get_token_ids(train_text1, test_text1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxiWTl7tIbY_"
      },
      "source": [
        "xtr_token = pad_sequences(xtr_token, maxlen=512, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "xtst_token = pad_sequences(xtst_token, maxlen=512, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aHomHaRIcVN"
      },
      "source": [
        "attention_mask_tr = []\n",
        "attention_mask_tst = []\n",
        "for sent in xtr_token:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_mask_tr.append(att_mask)\n",
        "\n",
        "for sent in xtst_token:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_mask_tst.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRy6BroQIOD3"
      },
      "source": [
        "train_input_text = torch.tensor(xtr_token)\n",
        "test_input_text = torch.tensor(xtst_token)\n",
        "\n",
        "# train_label = torch.tensor(trainY)\n",
        "# test_label = torch.tensor(testY)\n",
        "\n",
        "train_mask = torch.tensor(attention_mask_tr)\n",
        "test_mask = torch.tensor(attention_mask_tst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHM43U7N5h3h"
      },
      "source": [
        "## Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7AooyYZ5uIF"
      },
      "source": [
        "class FinalModel(nn.Module) :\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(FinalModel, self).__init__()\n",
        "    self.text_enc_model = BertMapping()\n",
        "    self.img_enc_model = TransformerMapping()\n",
        "    img_dims = 256\n",
        "    text_dims = 256\n",
        "\n",
        "  def cal_coeff(self, img_prob, text_prob) :\n",
        "    logp = torch.log(img_prob)\n",
        "    logp2 = torch.log(text_prob)\n",
        "    # print(\"logp\", logp.shape, \"logp2\", logp2.shape)\n",
        "    one_p = 1 - img_prob  # Don't compute gradient here\n",
        "    one_p.detach()\n",
        "    one_p2 = 1 - text_prob # Don't compute gradient here\n",
        "    one_p2.detach()\n",
        "    # M = 2\n",
        "    # Beta = 0.5\n",
        "    coeff = torch.sqrt(one_p2) * logp + torch.sqrt(one_p) * logp2\n",
        "    return coeff\n",
        "\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, img) :\n",
        "    img_enc = self.img_enc_model(img)\n",
        "    text_enc = self.text_enc_model(input_ids, attention_mask)\n",
        "    coeff = self.cal_coeff(img_enc, text_enc)\n",
        "    return coeff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzduJZMY6mWw"
      },
      "source": [
        "## Training code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CVndhwG6lbN",
        "outputId": "d63dd0b2-2144-41fb-8c82-bacfe16a3aa8"
      },
      "source": [
        "print(len(train_output_img), sum(train_output_img))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3617 tensor([2916.,  701.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO5QsGJY7Cvk",
        "outputId": "6aaa1ffa-956d-4abd-d408-2d9b4c83e52e"
      },
      "source": [
        "1/701"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0014265335235378032"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDdScg-37FAf",
        "outputId": "4be29202-d584-408d-d8fb-07e1ecfb9864"
      },
      "source": [
        "1/2916"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0003429355281207133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYro2CHN67BW"
      },
      "source": [
        "weights = [0.0003429355281207133, 0.0014265335235378032]\n",
        "sample_weights = [weights[t.argmax().int()] for t in train_output_img]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQp6uxYA67BX"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_input_text, train_mask, train_input_img,train_output_img)\n",
        "train_sampler = WeightedRandomSampler(weights=sample_weights, num_samples=3617)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhw-X8MB67BX"
      },
      "source": [
        "test_data = TensorDataset(test_input_text, test_mask, test_input_img, test_output_img)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQvqAXOS7gmf"
      },
      "source": [
        "def get_accuracy_from_logits(logits, labels):\n",
        "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "    soft_probs = (probs > 0.5).long()\n",
        "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm8prZsx2bQb"
      },
      "source": [
        "def get_labels_from_logits(logits) :\n",
        "  probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "  soft_probs = (probs > 0.5).long()\n",
        "  labels = soft_probs.squeeze()\n",
        "  return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ESEusP72Xr9"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def eval_model(model, val_loader) :\n",
        "  model.eval()\n",
        "  with torch.no_grad() :\n",
        "    final_out = []\n",
        "    final_lab = []\n",
        "    loss_val = 0\n",
        "    for idx, (val_input, val_mask, val_img, val_label) in enumerate(val_loader):\n",
        "      # try:\n",
        "        val_input = val_input.cuda()\n",
        "        val_mask = val_mask.cuda()\n",
        "        val_img = val_img.cuda()\n",
        "        val_label = val_label.cuda()\n",
        "        coeff = model(val_input, val_mask, val_img)\n",
        "        loss = -1*torch.mean(torch.sum(coeff*val_label,dim=1))\n",
        "        loss_val+= float(loss)\n",
        "        output = torch.argmax(coeff, dim=1)\n",
        "        # print(\"output_shape\", output.shape)\n",
        "        val_label = torch.argmax(val_label, dim=1)\n",
        "        # print(\"val_label_shape\", val_label.shape)\n",
        "        output = output.cpu().detach().numpy()\n",
        "        val_label = val_label.cpu().detach().numpy()\n",
        "        # print(output.shape)\n",
        "        # print(val_label.shape)\n",
        "        final_out.extend(list(output))\n",
        "        final_lab.extend(list(val_label))\n",
        "\n",
        "        del val_input\n",
        "        del val_label\n",
        "        del output\n",
        "        del coeff\n",
        "        del loss\n",
        "        del val_mask\n",
        "        torch.cuda.empty_cache()\n",
        "      # except:\n",
        "      #   print(\"error\") \n",
        "\n",
        "  return classification_report(final_lab, final_out), loss_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUTi-eCA7la4"
      },
      "source": [
        "def train(net, opti, train_loader, num_epochs, val_loader):\n",
        "  loss_train = []\n",
        "  loss_test = []\n",
        "  for epoch in range(num_epochs):\n",
        "    loss_val = 0\n",
        "    num_lab = 0\n",
        "    sum_lab = 0\n",
        "    for it, (text, mask,img, labels) in enumerate(train_loader):\n",
        "        #Clear gradients\n",
        "        opti.zero_grad()  \n",
        "        #Converting these to cuda tensors\n",
        "        text, mask, img, labels = text.cuda(), mask.cuda(), img.cuda(), labels.cuda()\n",
        "        num_lab += labels.shape[0]\n",
        "        sum_lab += torch.sum(labels)\n",
        "\n",
        "        #Obtaining the logits from the model\n",
        "        coeff = net(text, mask, img)\n",
        "\n",
        "        # print(\"labels_shape\", labels.shape)\n",
        "        #Computing loss\n",
        "        mul_out = coeff*labels\n",
        "        # print(\"mul_out\",mul_out.shape)\n",
        "        sum_out = torch.sum(mul_out, dim=1)\n",
        "        # print(\"sum_out\" , sum_out.shape)\n",
        "        loss = -1*torch.mean(sum_out)\n",
        "        # print(loss)\n",
        "        loss_val += float(loss.data)\n",
        "\n",
        "        #Backpropagating the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        #Optimization step\n",
        "        opti.step()\n",
        "\n",
        "        if (it + 1) % 20 == 0:\n",
        "            print(\"Iteration {} of epoch {} complete. Loss : {} \".format(it+1, epoch+1, loss.item()))\n",
        "\n",
        "        del text\n",
        "        del mask\n",
        "        del img\n",
        "        del labels\n",
        "        del loss\n",
        "        del mul_out\n",
        "        del sum_out\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print('Epoch [{}/{}], Loss:{:.4f}'.format(epoch+1, num_epochs, loss_val))\n",
        "    loss_train.append(loss_val)\n",
        "    if((epoch+1)%1==0) :\n",
        "      report, loss_t = eval_model(net, val_loader)\n",
        "      loss_test.append(loss_t)\n",
        "      print(\"loss_test\", loss_t)\n",
        "      print(\"classification_report\")\n",
        "      print(report)\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "    print(num_lab)\n",
        "    print(sum_lab)\n",
        "  return loss_train, loss_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0f2ec43be50249ffb8a23b5e6f19f83e",
            "97167c73d6624c7cadae502a36113660",
            "f283a905da1b4bd88e510e79c83599f7",
            "a1d4f5bd614a4fb5bbb2b15b27219a55",
            "99375ca69ae4478facbd9993d624087d",
            "b46e10dc90a3484a8fe953d320288299",
            "340807bd041f44c1b1413df1fc33164b",
            "e5b5bf41fc094196b0a2ff669229e08f"
          ]
        },
        "id": "pm7pODOr7p_M",
        "outputId": "c5ae1db8-ff9b-4fdf-cd43-2e77716b3bbd"
      },
      "source": [
        "net = FinalModel().to(device)\n",
        "# criterion = nn.BCEWithLogitsLoss()\n",
        "opti = optim.Adam(net.parameters(), lr = 1e-5)\n",
        "loss_train, loss_test = train(net, opti, train_dataloader, 20, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f2ec43be50249ffb8a23b5e6f19f83e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=624.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 20 of epoch 1 complete. Loss : 0.9707185626029968 \n",
            "Iteration 40 of epoch 1 complete. Loss : 0.9736417531967163 \n",
            "Iteration 60 of epoch 1 complete. Loss : 0.9649034738540649 \n",
            "Iteration 80 of epoch 1 complete. Loss : 0.9943276047706604 \n",
            "Iteration 100 of epoch 1 complete. Loss : 0.9665378332138062 \n",
            "Epoch [1/20], Loss:110.9994\n",
            "loss_test 30.999011278152466\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.32      0.46       746\n",
            "           1       0.26      0.78      0.39       226\n",
            "\n",
            "    accuracy                           0.42       972\n",
            "   macro avg       0.54      0.55      0.42       972\n",
            "weighted avg       0.69      0.42      0.44       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 2 complete. Loss : 0.9716498851776123 \n",
            "Iteration 40 of epoch 2 complete. Loss : 0.971420407295227 \n",
            "Iteration 60 of epoch 2 complete. Loss : 0.9751724004745483 \n",
            "Iteration 80 of epoch 2 complete. Loss : 0.9769095182418823 \n",
            "Iteration 100 of epoch 2 complete. Loss : 0.9516551494598389 \n",
            "Epoch [2/20], Loss:108.9375\n",
            "loss_test 29.325888693332672\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.67      0.72       746\n",
            "           1       0.27      0.40      0.32       226\n",
            "\n",
            "    accuracy                           0.61       972\n",
            "   macro avg       0.53      0.54      0.52       972\n",
            "weighted avg       0.67      0.61      0.63       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 3 complete. Loss : 0.9285831451416016 \n",
            "Iteration 40 of epoch 3 complete. Loss : 0.9128991961479187 \n",
            "Iteration 60 of epoch 3 complete. Loss : 0.891120195388794 \n",
            "Iteration 80 of epoch 3 complete. Loss : 0.9690214991569519 \n",
            "Iteration 100 of epoch 3 complete. Loss : 0.8850874304771423 \n",
            "Epoch [3/20], Loss:103.8910\n",
            "loss_test 29.186712741851807\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.57      0.69       746\n",
            "           1       0.34      0.75      0.47       226\n",
            "\n",
            "    accuracy                           0.61       972\n",
            "   macro avg       0.61      0.66      0.58       972\n",
            "weighted avg       0.76      0.61      0.64       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 4 complete. Loss : 0.8061697483062744 \n",
            "Iteration 40 of epoch 4 complete. Loss : 0.7357590198516846 \n",
            "Iteration 60 of epoch 4 complete. Loss : 0.8166745901107788 \n",
            "Iteration 80 of epoch 4 complete. Loss : 0.8258661031723022 \n",
            "Iteration 100 of epoch 4 complete. Loss : 0.8007138967514038 \n",
            "Epoch [4/20], Loss:92.3257\n",
            "loss_test 27.8604434132576\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.64      0.75       746\n",
            "           1       0.38      0.73      0.50       226\n",
            "\n",
            "    accuracy                           0.66       972\n",
            "   macro avg       0.64      0.69      0.62       972\n",
            "weighted avg       0.77      0.66      0.69       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 5 complete. Loss : 0.8290601968765259 \n",
            "Iteration 40 of epoch 5 complete. Loss : 0.8081989288330078 \n",
            "Iteration 60 of epoch 5 complete. Loss : 0.6830712556838989 \n",
            "Iteration 80 of epoch 5 complete. Loss : 0.712114691734314 \n",
            "Iteration 100 of epoch 5 complete. Loss : 0.7306851744651794 \n",
            "Epoch [5/20], Loss:86.1010\n",
            "loss_test 27.973537921905518\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.60      0.72       746\n",
            "           1       0.38      0.80      0.51       226\n",
            "\n",
            "    accuracy                           0.65       972\n",
            "   macro avg       0.64      0.70      0.62       972\n",
            "weighted avg       0.78      0.65      0.67       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 6 complete. Loss : 0.8620424270629883 \n",
            "Iteration 40 of epoch 6 complete. Loss : 0.7030458450317383 \n",
            "Iteration 60 of epoch 6 complete. Loss : 0.6904302835464478 \n",
            "Iteration 80 of epoch 6 complete. Loss : 0.7859535813331604 \n",
            "Iteration 100 of epoch 6 complete. Loss : 0.6451025605201721 \n",
            "Epoch [6/20], Loss:82.3690\n",
            "loss_test 25.939472198486328\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.73      0.80       746\n",
            "           1       0.44      0.71      0.54       226\n",
            "\n",
            "    accuracy                           0.72       972\n",
            "   macro avg       0.67      0.72      0.67       972\n",
            "weighted avg       0.79      0.72      0.74       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 7 complete. Loss : 0.7551490664482117 \n",
            "Iteration 40 of epoch 7 complete. Loss : 0.6154680252075195 \n",
            "Iteration 60 of epoch 7 complete. Loss : 0.7508345246315002 \n",
            "Iteration 80 of epoch 7 complete. Loss : 0.7268557548522949 \n",
            "Iteration 100 of epoch 7 complete. Loss : 0.7262778282165527 \n",
            "Epoch [7/20], Loss:79.2909\n",
            "loss_test 25.724718987941742\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.72      0.80       746\n",
            "           1       0.46      0.79      0.58       226\n",
            "\n",
            "    accuracy                           0.73       972\n",
            "   macro avg       0.69      0.75      0.69       972\n",
            "weighted avg       0.81      0.73      0.75       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 8 complete. Loss : 0.6291360855102539 \n",
            "Iteration 40 of epoch 8 complete. Loss : 0.6041079163551331 \n",
            "Iteration 60 of epoch 8 complete. Loss : 0.7334688901901245 \n",
            "Iteration 80 of epoch 8 complete. Loss : 0.6040034294128418 \n",
            "Iteration 100 of epoch 8 complete. Loss : 0.6429890394210815 \n",
            "Epoch [8/20], Loss:75.0859\n",
            "loss_test 26.69127857685089\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.63      0.75       746\n",
            "           1       0.41      0.83      0.55       226\n",
            "\n",
            "    accuracy                           0.68       972\n",
            "   macro avg       0.67      0.73      0.65       972\n",
            "weighted avg       0.80      0.68      0.70       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 9 complete. Loss : 0.6480388641357422 \n",
            "Iteration 40 of epoch 9 complete. Loss : 0.5826013684272766 \n",
            "Iteration 60 of epoch 9 complete. Loss : 0.6089082956314087 \n",
            "Iteration 80 of epoch 9 complete. Loss : 0.5859088897705078 \n",
            "Iteration 100 of epoch 9 complete. Loss : 0.5898516774177551 \n",
            "Epoch [9/20], Loss:72.4444\n",
            "loss_test 23.859050571918488\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.79      0.84       746\n",
            "           1       0.50      0.70      0.58       226\n",
            "\n",
            "    accuracy                           0.77       972\n",
            "   macro avg       0.70      0.74      0.71       972\n",
            "weighted avg       0.80      0.77      0.78       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 10 complete. Loss : 0.7172160148620605 \n",
            "Iteration 40 of epoch 10 complete. Loss : 0.6363312005996704 \n",
            "Iteration 60 of epoch 10 complete. Loss : 0.6518169045448303 \n",
            "Iteration 80 of epoch 10 complete. Loss : 0.7120161056518555 \n",
            "Iteration 100 of epoch 10 complete. Loss : 0.6216545104980469 \n",
            "Epoch [10/20], Loss:70.3241\n",
            "loss_test 23.973007202148438\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.78      0.84       746\n",
            "           1       0.50      0.71      0.58       226\n",
            "\n",
            "    accuracy                           0.76       972\n",
            "   macro avg       0.70      0.74      0.71       972\n",
            "weighted avg       0.80      0.76      0.78       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 11 complete. Loss : 0.5849833488464355 \n",
            "Iteration 40 of epoch 11 complete. Loss : 0.5420162081718445 \n",
            "Iteration 60 of epoch 11 complete. Loss : 0.5638843178749084 \n",
            "Iteration 80 of epoch 11 complete. Loss : 0.6759610176086426 \n",
            "Iteration 100 of epoch 11 complete. Loss : 0.6664450764656067 \n",
            "Epoch [11/20], Loss:68.2903\n",
            "loss_test 25.178703606128693\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.71      0.80       746\n",
            "           1       0.45      0.80      0.58       226\n",
            "\n",
            "    accuracy                           0.73       972\n",
            "   macro avg       0.68      0.75      0.69       972\n",
            "weighted avg       0.81      0.73      0.75       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 12 complete. Loss : 0.53275465965271 \n",
            "Iteration 40 of epoch 12 complete. Loss : 0.6185985803604126 \n",
            "Iteration 60 of epoch 12 complete. Loss : 0.6692624092102051 \n",
            "Iteration 80 of epoch 12 complete. Loss : 0.5019644498825073 \n",
            "Iteration 100 of epoch 12 complete. Loss : 0.6061305999755859 \n",
            "Epoch [12/20], Loss:65.4540\n",
            "loss_test 24.585479736328125\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.74      0.82       746\n",
            "           1       0.47      0.79      0.59       226\n",
            "\n",
            "    accuracy                           0.75       972\n",
            "   macro avg       0.70      0.76      0.70       972\n",
            "weighted avg       0.82      0.75      0.77       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 13 complete. Loss : 0.5386723279953003 \n",
            "Iteration 40 of epoch 13 complete. Loss : 0.4732133448123932 \n",
            "Iteration 60 of epoch 13 complete. Loss : 0.5954468846321106 \n",
            "Iteration 80 of epoch 13 complete. Loss : 0.526741623878479 \n",
            "Iteration 100 of epoch 13 complete. Loss : 0.5949380397796631 \n",
            "Epoch [13/20], Loss:62.5666\n",
            "loss_test 23.48120939731598\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.78      0.84       746\n",
            "           1       0.50      0.75      0.60       226\n",
            "\n",
            "    accuracy                           0.77       972\n",
            "   macro avg       0.71      0.76      0.72       972\n",
            "weighted avg       0.82      0.77      0.78       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 14 complete. Loss : 0.5924556851387024 \n",
            "Iteration 40 of epoch 14 complete. Loss : 0.5597586035728455 \n",
            "Iteration 60 of epoch 14 complete. Loss : 0.48949119448661804 \n",
            "Iteration 80 of epoch 14 complete. Loss : 0.5721861720085144 \n",
            "Iteration 100 of epoch 14 complete. Loss : 0.5874293446540833 \n",
            "Epoch [14/20], Loss:60.6967\n",
            "loss_test 23.794603049755096\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.76      0.83       746\n",
            "           1       0.50      0.77      0.60       226\n",
            "\n",
            "    accuracy                           0.76       972\n",
            "   macro avg       0.71      0.77      0.72       972\n",
            "weighted avg       0.82      0.76      0.78       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 15 complete. Loss : 0.5502392053604126 \n",
            "Iteration 40 of epoch 15 complete. Loss : 0.5076155662536621 \n",
            "Iteration 60 of epoch 15 complete. Loss : 0.4057045876979828 \n",
            "Iteration 80 of epoch 15 complete. Loss : 0.49763691425323486 \n",
            "Iteration 100 of epoch 15 complete. Loss : 0.5936383008956909 \n",
            "Epoch [15/20], Loss:58.2780\n",
            "loss_test 22.62709254026413\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.82      0.86       746\n",
            "           1       0.54      0.69      0.60       226\n",
            "\n",
            "    accuracy                           0.79       972\n",
            "   macro avg       0.72      0.75      0.73       972\n",
            "weighted avg       0.81      0.79      0.80       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 16 complete. Loss : 0.5344115495681763 \n",
            "Iteration 40 of epoch 16 complete. Loss : 0.5423504710197449 \n",
            "Iteration 60 of epoch 16 complete. Loss : 0.4785468280315399 \n",
            "Iteration 80 of epoch 16 complete. Loss : 0.4570710062980652 \n",
            "Iteration 100 of epoch 16 complete. Loss : 0.47992053627967834 \n",
            "Epoch [16/20], Loss:55.6995\n",
            "loss_test 21.28721410036087\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.88       746\n",
            "           1       0.63      0.56      0.59       226\n",
            "\n",
            "    accuracy                           0.82       972\n",
            "   macro avg       0.75      0.73      0.74       972\n",
            "weighted avg       0.81      0.82      0.82       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 17 complete. Loss : 0.5132558941841125 \n",
            "Iteration 40 of epoch 17 complete. Loss : 0.560772716999054 \n",
            "Iteration 60 of epoch 17 complete. Loss : 0.43013250827789307 \n",
            "Iteration 80 of epoch 17 complete. Loss : 0.488663911819458 \n",
            "Iteration 100 of epoch 17 complete. Loss : 0.42591625452041626 \n",
            "Epoch [17/20], Loss:54.3919\n",
            "loss_test 21.42352432012558\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.84      0.87       746\n",
            "           1       0.56      0.67      0.61       226\n",
            "\n",
            "    accuracy                           0.80       972\n",
            "   macro avg       0.73      0.75      0.74       972\n",
            "weighted avg       0.82      0.80      0.81       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 18 complete. Loss : 0.4696946442127228 \n",
            "Iteration 40 of epoch 18 complete. Loss : 0.5176377892494202 \n",
            "Iteration 60 of epoch 18 complete. Loss : 0.49631211161613464 \n",
            "Iteration 80 of epoch 18 complete. Loss : 0.3938159644603729 \n",
            "Iteration 100 of epoch 18 complete. Loss : 0.4204486608505249 \n",
            "Epoch [18/20], Loss:50.7217\n",
            "loss_test 20.85187476873398\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88       746\n",
            "           1       0.60      0.62      0.61       226\n",
            "\n",
            "    accuracy                           0.82       972\n",
            "   macro avg       0.74      0.75      0.75       972\n",
            "weighted avg       0.82      0.82      0.82       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 19 complete. Loss : 0.4131265878677368 \n",
            "Iteration 40 of epoch 19 complete. Loss : 0.437081515789032 \n",
            "Iteration 60 of epoch 19 complete. Loss : 0.47897693514823914 \n",
            "Iteration 80 of epoch 19 complete. Loss : 0.4329417049884796 \n",
            "Iteration 100 of epoch 19 complete. Loss : 0.36532148718833923 \n",
            "Epoch [19/20], Loss:50.2478\n",
            "loss_test 21.143788754940033\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.83      0.87       746\n",
            "           1       0.56      0.69      0.62       226\n",
            "\n",
            "    accuracy                           0.80       972\n",
            "   macro avg       0.73      0.76      0.74       972\n",
            "weighted avg       0.82      0.80      0.81       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n",
            "Iteration 20 of epoch 20 complete. Loss : 0.45072513818740845 \n",
            "Iteration 40 of epoch 20 complete. Loss : 0.4007635712623596 \n",
            "Iteration 60 of epoch 20 complete. Loss : 0.45468395948410034 \n",
            "Iteration 80 of epoch 20 complete. Loss : 0.3764719069004059 \n",
            "Iteration 100 of epoch 20 complete. Loss : 0.4147280752658844 \n",
            "Epoch [20/20], Loss:48.1784\n",
            "loss_test 20.000290900468826\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88       746\n",
            "           1       0.61      0.62      0.61       226\n",
            "\n",
            "    accuracy                           0.82       972\n",
            "   macro avg       0.75      0.75      0.75       972\n",
            "weighted avg       0.82      0.82      0.82       972\n",
            "\n",
            "--------------------------------------------------------------\n",
            "3617\n",
            "tensor(3617., device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PncdEkWQ7uqQ"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJgq1se87x3_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "1dde1e5c-1992-4c7d-bca4-3bcd42a16d42"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(loss_train, label=\"loss_train\")\n",
        "plt.plot(loss_test, label=\"loss_test\")\n",
        "plt.plot([17,17], [0, 80])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vRyPmTn708w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "09827606-be1b-4fac-b3f8-a2575a93c21e"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(loss_train, label=\"loss_train\")\n",
        "plt.plot(loss_test, label=\"loss_test\")\n",
        "plt.plot([17,17], [0, 111])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km6oX8qH74T-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-afK3Od77d4"
      },
      "source": [
        "print(\"classification_report\")\n",
        "print(eval_model(net, test_dataloader))\n",
        "print(\"--------------------------------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-1t-yvp7-Xz"
      },
      "source": [
        "torch.save(net.state_dict(), \"/content/drive/My Drive/multi-modal/img_embed_dict.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}