{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multimodal_text_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "204ee253f28e47f09ee3ff46afb0ec88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f5defa998bba4c03a4a286f37a5caf3e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d36e436f53242318dc5038a33599f84",
              "IPY_MODEL_552e3f3c154c41af978cf60a3d510934"
            ]
          }
        },
        "f5defa998bba4c03a4a286f37a5caf3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d36e436f53242318dc5038a33599f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b00057d728424fa699d35253331fc778",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_914a88a8619a436785a5b12dd72380aa"
          }
        },
        "552e3f3c154c41af978cf60a3d510934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70829e95635343189d9dc942b3dbe1d1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 621kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f4f88992e99e4577b4a799961c8d2973"
          }
        },
        "b00057d728424fa699d35253331fc778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "914a88a8619a436785a5b12dd72380aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70829e95635343189d9dc942b3dbe1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f4f88992e99e4577b4a799961c8d2973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y38aRAsXDGTd",
        "outputId": "976aa555-9353-49bd-e763-15e8a2ecb9dc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAwSSGLWHEy9",
        "outputId": "6fa02b55-1a18-44fd-a3ae-dbac9337aa71"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.5MB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 36.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 37.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=c5d78288c65206221101cdf6055fafd26c82b02159e313e9baad828b4b97bb61\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM4wnEpnD1UN"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.nn import Parameter\n",
        "from transformers import BertModel\n",
        "from transformers import BertConfig\n",
        "from transformers import BertTokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxFI8QDCLF8Z"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE_-QaN0DX6X"
      },
      "source": [
        "def get_df(file):\n",
        "    return pd.read_csv(file,sep = '\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QECKknXvD9CD"
      },
      "source": [
        "train_df = get_df('/content/drive/My Drive/fake_news_dataset/mediaeval2016/train_posts.txt')\n",
        "test_df = get_df('/content/drive/My Drive/fake_news_dataset/mediaeval2016/test_posts.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "XeesQVhmEN-G",
        "outputId": "36377d0b-aad1-4cef-b9d7-e39a9ac136fc"
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_id</th>\n",
              "      <th>post_text</th>\n",
              "      <th>user_id</th>\n",
              "      <th>image_id(s)</th>\n",
              "      <th>username</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>324597532548276224</td>\n",
              "      <td>Don't need feds to solve the #bostonbombing wh...</td>\n",
              "      <td>886672620</td>\n",
              "      <td>boston_fake_03,boston_fake_35</td>\n",
              "      <td>SantaCruzShred</td>\n",
              "      <td>Wed Apr 17 18:57:37 +0000 2013</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>325145334739267584</td>\n",
              "      <td>PIC: Comparison of #Boston suspect Sunil Tripa...</td>\n",
              "      <td>21992286</td>\n",
              "      <td>boston_fake_23</td>\n",
              "      <td>Oscar_Wang</td>\n",
              "      <td>Fri Apr 19 07:14:23 +0000 2013</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>325152091423248385</td>\n",
              "      <td>I'm not completely convinced that it's this Su...</td>\n",
              "      <td>16428755</td>\n",
              "      <td>boston_fake_34</td>\n",
              "      <td>jamwil</td>\n",
              "      <td>Fri Apr 19 07:41:14 +0000 2013</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>324554646976868352</td>\n",
              "      <td>Brutal lo que se puede conseguir en colaboraci...</td>\n",
              "      <td>303138574</td>\n",
              "      <td>boston_fake_03,boston_fake_35</td>\n",
              "      <td>rubenson80</td>\n",
              "      <td>Wed Apr 17 16:07:12 +0000 2013</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>324315545572896768</td>\n",
              "      <td>4chan and the bombing. just throwing it out th...</td>\n",
              "      <td>180460772</td>\n",
              "      <td>boston_fake_15</td>\n",
              "      <td>Slimlenny</td>\n",
              "      <td>Wed Apr 17 00:17:06 +0000 2013</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15624</th>\n",
              "      <td>578433150071775232</td>\n",
              "      <td>Un prÃ©sentateur de la ZDF confesse avoir truqu...</td>\n",
              "      <td>257551211</td>\n",
              "      <td>varoufakis_1</td>\n",
              "      <td>Cdt_Sylvestre</td>\n",
              "      <td>Thu Mar 19 05:49:44 +0000 2015</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15625</th>\n",
              "      <td>578433646597656576</td>\n",
              "      <td>Oh les kleine menteurs \\\"@CorineBarella: Un pr...</td>\n",
              "      <td>27575883</td>\n",
              "      <td>varoufakis_1</td>\n",
              "      <td>damomarc</td>\n",
              "      <td>Thu Mar 19 05:51:42 +0000 2015</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15626</th>\n",
              "      <td>578486910491996160</td>\n",
              "      <td>Este es el programa de ZDF en el que confirman...</td>\n",
              "      <td>2049211</td>\n",
              "      <td>varoufakis_1</td>\n",
              "      <td>javierpascual</td>\n",
              "      <td>Thu Mar 19 09:23:21 +0000 2015</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15627</th>\n",
              "      <td>578505023912591360</td>\n",
              "      <td>11.34 - wir haben FAST Mittag â–¶ Riesen Verwirr...</td>\n",
              "      <td>262222386</td>\n",
              "      <td>varoufakis_1</td>\n",
              "      <td>aotto1968_2</td>\n",
              "      <td>Thu Mar 19 10:35:20 +0000 2015</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15628</th>\n",
              "      <td>578305144380612609</td>\n",
              "      <td>Sorry, @yanisvaroufakis! https://t.co/BSkYrbII...</td>\n",
              "      <td>19072286</td>\n",
              "      <td>varoufakis_1</td>\n",
              "      <td>janboehm</td>\n",
              "      <td>Wed Mar 18 21:21:05 +0000 2015</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15629 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  post_id  ... label\n",
              "0      324597532548276224  ...  fake\n",
              "1      325145334739267584  ...  fake\n",
              "2      325152091423248385  ...  fake\n",
              "3      324554646976868352  ...  fake\n",
              "4      324315545572896768  ...  fake\n",
              "...                   ...  ...   ...\n",
              "15624  578433150071775232  ...  fake\n",
              "15625  578433646597656576  ...  fake\n",
              "15626  578486910491996160  ...  fake\n",
              "15627  578505023912591360  ...  fake\n",
              "15628  578305144380612609  ...  fake\n",
              "\n",
              "[15629 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "204ee253f28e47f09ee3ff46afb0ec88",
            "f5defa998bba4c03a4a286f37a5caf3e",
            "3d36e436f53242318dc5038a33599f84",
            "552e3f3c154c41af978cf60a3d510934",
            "b00057d728424fa699d35253331fc778",
            "914a88a8619a436785a5b12dd72380aa",
            "70829e95635343189d9dc942b3dbe1d1",
            "f4f88992e99e4577b4a799961c8d2973"
          ]
        },
        "id": "FYqh0-vMIJbl",
        "outputId": "754e5258-0ea7-4c38-a5cd-82fccdf5a19d"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "204ee253f28e47f09ee3ff46afb0ec88",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV0OCDseN2-F",
        "outputId": "485d6bfa-7b0f-458e-e727-b532953b6d9f"
      },
      "source": [
        "r = 0\n",
        "f = 0\n",
        "for x in train_df['label'] :\n",
        "  if(x=='real') :\n",
        "    r+=1\n",
        "  else :\n",
        "    f+=1\n",
        "\n",
        "print(r)\n",
        "print(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6225\n",
            "9404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywijz88SM3aT"
      },
      "source": [
        "x_train = train_df['post_text']\n",
        "x_test = test_df['post_text']\n",
        "y_train = train_df['label'].eq('real').astype(int)\n",
        "y_test = test_df['label'].eq('real').astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVYlnuFZIi68"
      },
      "source": [
        "def get_token_ids(x_train, x_test):\n",
        "    \n",
        "    token_tr = []\n",
        "    token_tst = []\n",
        "    count = 0\n",
        "    for sent in x_train :\n",
        "        tokens = tokenizer.encode(sent, add_special_tokens = True, max_length=512)\n",
        "        token_tr.append(tokens)\n",
        "        count+=1\n",
        "        if(count%1000==0):\n",
        "            print(count)\n",
        "    \n",
        "    for sent1 in x_test :\n",
        "        tokens1 = tokenizer.encode(sent1, add_special_tokens = True, max_length=512)\n",
        "        token_tst.append(tokens1)\n",
        "        count+=1\n",
        "        if(count%1000==0):\n",
        "            print(count)\n",
        "            \n",
        "    return token_tr, token_tst "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUSgvPHsIYly",
        "outputId": "c88f8328-9119-4f9b-cd2f-73590a6c20ec"
      },
      "source": [
        "xtr_token, xtst_token = get_token_ids(x_train, x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxiWTl7tIbY_"
      },
      "source": [
        "xtr_token = pad_sequences(xtr_token, maxlen=512, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "xtst_token = pad_sequences(xtst_token, maxlen=512, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aHomHaRIcVN"
      },
      "source": [
        "attention_mask_tr = []\n",
        "attention_mask_tst = []\n",
        "for sent in xtr_token:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_mask_tr.append(att_mask)\n",
        "\n",
        "for sent in xtst_token:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_mask_tst.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRy6BroQIOD3"
      },
      "source": [
        "train_input = torch.tensor(xtr_token)\n",
        "test_input = torch.tensor(xtst_token)\n",
        "\n",
        "train_label = torch.tensor(y_train)\n",
        "test_label = torch.tensor(y_test)\n",
        "\n",
        "train_mask = torch.tensor(attention_mask_tr)\n",
        "test_mask = torch.tensor(attention_mask_tst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZgp_Z4-KaDY"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_input, train_mask, train_label)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xjrprf8KfLE"
      },
      "source": [
        "# Create the DataLoader for our validation set.\n",
        "test_data = TensorDataset(test_input, test_mask, test_label)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAO15QEyKin9"
      },
      "source": [
        "def freeze_layers(model):\n",
        "    for child in model.children():\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgTj1A56EYgm"
      },
      "source": [
        "class BertMapping(nn.Module):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(BertMapping, self).__init__()\n",
        "        # bert_config = BertConfig.from_json_file(opt.bert_config_file)\n",
        "        bert_config = BertConfig.from_pretrained('bert-base-uncased')\n",
        "        self.bert = BertModel(bert_config)\n",
        "        # self.bert.load_state_dict(torch.load(opt.init_checkpoint, map_location='cpu'))\n",
        "        freeze_layers(self.bert)\n",
        "        final_dims = 256\n",
        "        # self.txt_stru = opt.txt_stru\n",
        "\n",
        "        # if opt.txt_stru == 'pooling':\n",
        "        #     self.dropout = nn.Dropout(bert_config.hidden_dropout_prob)\n",
        "        #     self.mapping = nn.Linear(bert_config.hidden_size, opt.final_dims)\n",
        "        # elif opt.txt_stru == 'cnn':\n",
        "        Ks = [1, 2, 3]\n",
        "        in_channel = 1\n",
        "        out_channel = 512\n",
        "        embedding_dim = bert_config.hidden_size\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(in_channel, out_channel, (K, embedding_dim)) for K in Ks])\n",
        "        self.dropout = nn.Dropout(bert_config.hidden_dropout_prob)\n",
        "        self.mapping = nn.Linear(len(Ks)*out_channel, final_dims)\n",
        "        self.cls_layer = nn.Linear(final_dims, 1)\n",
        "        # elif opt.txt_stru == 'rnn':\n",
        "        #     embedding_dim = bert_config.hidden_size\n",
        "        #     self.bi_gru = opt.bi_gru\n",
        "        #     self.rnn = nn.GRU(embedding_dim, opt.embed_size, opt.num_layers, batch_first=True, bidirectional=opt.bi_gru)\n",
        "        #     self.dropout = nn.Dropout(bert_config.hidden_dropout_prob)\n",
        "        #     self.mapping = nn.Linear(opt.embed_size, opt.final_dims)\n",
        "        # elif opt.txt_stru == 'trans':\n",
        "        #     bert_config = BertConfig.from_json_file(opt.img_trans_cfg)\n",
        "        #     self.layer = bert.BERTLayer(bert_config)\n",
        "        #     self.dropout = nn.Dropout(bert_config.hidden_dropout_prob)\n",
        "        #     self.mapping = nn.Linear(768, opt.final_dims)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids,attention_mask=attention_mask, return_dict=True)\n",
        "        # if self.txt_stru == 'pooling':\n",
        "        #     output = self.mapping(all_encoder_layers[-1])\n",
        "        #     output = torch.mean(output, 1)\n",
        "        #     code = output\n",
        "        # elif self.txt_stru == 'cnn':\n",
        "        x = outputs.last_hidden_state.unsqueeze(1)  # (batch_size, 1, token_num, embedding_dim)\n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(batch_size, out_channel, W), ...]*len(Ks)\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
        "        output = torch.cat(x, 1)\n",
        "        # elif self.txt_stru == 'rnn':\n",
        "        #     x = all_encoder_layers[-1]  # (batch_size, token_num, embedding_dim)\n",
        "        #     packed = pack_padded_sequence(x, lengths, batch_first=True)\n",
        "        #     # Forward propagate RNN\n",
        "        #     out, _ = self.rnn(packed)\n",
        "        #     # Reshape *final* output to (batch_size, hidden_size)\n",
        "        #     padded = pad_packed_sequence(out, batch_first=True)\n",
        "        #     cap_emb, cap_len = padded\n",
        "        #     if self.bi_gru:\n",
        "        #         cap_emb = (cap_emb[:, :, :cap_emb.size(2) / 2] + cap_emb[:, :, cap_emb.size(2) / 2:]) / 2\n",
        "        #     else:\n",
        "        #         cap_emb = cap_emb\n",
        "        #     output = torch.mean(cap_emb, 1)\n",
        "        # elif self.txt_stru == 'trans':\n",
        "\n",
        "        #     hidden_states = self.mapping(all_encoder_layers[-1])\n",
        "        #     extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "        #     extended_attention_mask = extended_attention_mask.float()\n",
        "        #     extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        #     hidden_states = self.layer(hidden_states, extended_attention_mask)\n",
        "        #     # output = hidden_states[:, 0, :]\n",
        "        #     output = torch.mean(hidden_states, 1)\n",
        "\n",
        "        output = self.dropout(output)\n",
        "        code = self.mapping(output)\n",
        "        # code = F.tanh(code)\n",
        "        code = F.normalize(code, p=2, dim=1)\n",
        "        code = self.cls_layer(code)\n",
        "        return code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MPEjydwT8oC"
      },
      "source": [
        "def get_accuracy_from_logits(logits, labels):\n",
        "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "    soft_probs = (probs > 0.5).long()\n",
        "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv0Jc_vlH9He"
      },
      "source": [
        "def train(net, criterion, opti, train_loader, num_epochs, val_loader):\n",
        "  for epoch in range(num_epochs):\n",
        "    loss_val = 0\n",
        "    for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "        #Clear gradients\n",
        "        opti.zero_grad()  \n",
        "        #Converting these to cuda tensors\n",
        "        seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "\n",
        "        #Obtaining the logits from the model\n",
        "        logits = net(seq, attn_masks)\n",
        "\n",
        "        #Computing loss\n",
        "        loss = criterion(logits.squeeze(-1), labels.float())\n",
        "        loss_val += loss.data\n",
        "\n",
        "        #Backpropagating the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        #Optimization step\n",
        "        opti.step()\n",
        "\n",
        "        if (it + 1) % 20 == 0:\n",
        "            acc = get_accuracy_from_logits(logits, labels)\n",
        "            print(\"Iteration {} of epoch {} complete. Loss : {} Accuracy : {}\".format(it+1, epoch+1, loss.item(), acc))\n",
        "\n",
        "        del seq\n",
        "        del attn_masks\n",
        "        del labels\n",
        "        del logits\n",
        "        del loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print('Epoch [{}/{}], Loss:{:.4f}'.format(epoch+1, num_epochs, loss_val))\n",
        "    # if((epoch+1)%2==0) :\n",
        "    #   print(\"classification_report\")\n",
        "    #   print(eval_model(net, val_loader))\n",
        "    # print(\"--------------------------------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N92MQb-BQVYD"
      },
      "source": [
        "net = BertMapping().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "opti = optim.Adam(net.parameters(), lr = 2e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmguZTojQdd7",
        "outputId": "578bb576-5bf8-4276-c314-2d51f24650c7"
      },
      "source": [
        "train(net, criterion, opti, train_dataloader, 20, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 20 of epoch 1 complete. Loss : 0.6427617073059082 Accuracy : 0.6875\n",
            "Iteration 40 of epoch 1 complete. Loss : 0.7217259407043457 Accuracy : 0.46875\n",
            "Iteration 60 of epoch 1 complete. Loss : 0.6871233582496643 Accuracy : 0.5625\n",
            "Iteration 80 of epoch 1 complete. Loss : 0.650540292263031 Accuracy : 0.65625\n",
            "Iteration 100 of epoch 1 complete. Loss : 0.588671088218689 Accuracy : 0.8125\n",
            "Iteration 120 of epoch 1 complete. Loss : 0.7006068229675293 Accuracy : 0.53125\n",
            "Iteration 140 of epoch 1 complete. Loss : 0.6626191139221191 Accuracy : 0.625\n",
            "Iteration 160 of epoch 1 complete. Loss : 0.6868983507156372 Accuracy : 0.5625\n",
            "Iteration 180 of epoch 1 complete. Loss : 0.6990219354629517 Accuracy : 0.53125\n",
            "Iteration 200 of epoch 1 complete. Loss : 0.6481145620346069 Accuracy : 0.65625\n",
            "Iteration 220 of epoch 1 complete. Loss : 0.6750702261924744 Accuracy : 0.59375\n",
            "Iteration 240 of epoch 1 complete. Loss : 0.6965141296386719 Accuracy : 0.53125\n",
            "Iteration 260 of epoch 1 complete. Loss : 0.718975841999054 Accuracy : 0.46875\n",
            "Iteration 280 of epoch 1 complete. Loss : 0.6520167589187622 Accuracy : 0.65625\n",
            "Iteration 300 of epoch 1 complete. Loss : 0.6736124157905579 Accuracy : 0.59375\n",
            "Iteration 320 of epoch 1 complete. Loss : 0.7579077482223511 Accuracy : 0.375\n",
            "Iteration 340 of epoch 1 complete. Loss : 0.735177755355835 Accuracy : 0.4375\n",
            "Iteration 360 of epoch 1 complete. Loss : 0.7004033327102661 Accuracy : 0.53125\n",
            "Iteration 380 of epoch 1 complete. Loss : 0.6881366968154907 Accuracy : 0.5625\n",
            "Iteration 400 of epoch 1 complete. Loss : 0.6615248322486877 Accuracy : 0.625\n",
            "Iteration 420 of epoch 1 complete. Loss : 0.6333816051483154 Accuracy : 0.6875\n",
            "Iteration 440 of epoch 1 complete. Loss : 0.6600311994552612 Accuracy : 0.625\n",
            "Iteration 460 of epoch 1 complete. Loss : 0.6867204904556274 Accuracy : 0.5625\n",
            "Iteration 480 of epoch 1 complete. Loss : 0.7173771858215332 Accuracy : 0.46875\n",
            "Epoch [1/20], Loss:328.4706\n",
            "Iteration 20 of epoch 2 complete. Loss : 0.6691985130310059 Accuracy : 0.59375\n",
            "Iteration 40 of epoch 2 complete. Loss : 0.6970958709716797 Accuracy : 0.53125\n",
            "Iteration 60 of epoch 2 complete. Loss : 0.6629003882408142 Accuracy : 0.625\n",
            "Iteration 80 of epoch 2 complete. Loss : 0.6740117073059082 Accuracy : 0.5625\n",
            "Iteration 100 of epoch 2 complete. Loss : 0.6612802743911743 Accuracy : 0.59375\n",
            "Iteration 120 of epoch 2 complete. Loss : 0.6546750068664551 Accuracy : 0.65625\n",
            "Iteration 140 of epoch 2 complete. Loss : 0.6413615345954895 Accuracy : 0.6875\n",
            "Iteration 160 of epoch 2 complete. Loss : 0.676741898059845 Accuracy : 0.5625\n",
            "Iteration 180 of epoch 2 complete. Loss : 0.6601247787475586 Accuracy : 0.65625\n",
            "Iteration 200 of epoch 2 complete. Loss : 0.6196846961975098 Accuracy : 0.71875\n",
            "Iteration 220 of epoch 2 complete. Loss : 0.6554122567176819 Accuracy : 0.78125\n",
            "Iteration 240 of epoch 2 complete. Loss : 0.6638134717941284 Accuracy : 0.5625\n",
            "Iteration 260 of epoch 2 complete. Loss : 0.5711029767990112 Accuracy : 0.84375\n",
            "Iteration 280 of epoch 2 complete. Loss : 0.5971616506576538 Accuracy : 0.8125\n",
            "Iteration 300 of epoch 2 complete. Loss : 0.6155633330345154 Accuracy : 0.75\n",
            "Iteration 320 of epoch 2 complete. Loss : 0.6711928844451904 Accuracy : 0.5625\n",
            "Iteration 340 of epoch 2 complete. Loss : 0.6293585896492004 Accuracy : 0.6875\n",
            "Iteration 360 of epoch 2 complete. Loss : 0.60898756980896 Accuracy : 0.71875\n",
            "Iteration 380 of epoch 2 complete. Loss : 0.6426122188568115 Accuracy : 0.625\n",
            "Iteration 400 of epoch 2 complete. Loss : 0.5880960822105408 Accuracy : 0.78125\n",
            "Iteration 420 of epoch 2 complete. Loss : 0.649504542350769 Accuracy : 0.5625\n",
            "Iteration 440 of epoch 2 complete. Loss : 0.6413924694061279 Accuracy : 0.6875\n",
            "Iteration 460 of epoch 2 complete. Loss : 0.6636884212493896 Accuracy : 0.59375\n",
            "Iteration 480 of epoch 2 complete. Loss : 0.6383521556854248 Accuracy : 0.59375\n",
            "Epoch [2/20], Loss:315.8613\n",
            "Iteration 20 of epoch 3 complete. Loss : 0.6795850992202759 Accuracy : 0.59375\n",
            "Iteration 40 of epoch 3 complete. Loss : 0.6065696477890015 Accuracy : 0.6875\n",
            "Iteration 60 of epoch 3 complete. Loss : 0.5918508768081665 Accuracy : 0.75\n",
            "Iteration 80 of epoch 3 complete. Loss : 0.5976462364196777 Accuracy : 0.75\n",
            "Iteration 100 of epoch 3 complete. Loss : 0.6363608837127686 Accuracy : 0.6875\n",
            "Iteration 120 of epoch 3 complete. Loss : 0.6095277667045593 Accuracy : 0.71875\n",
            "Iteration 140 of epoch 3 complete. Loss : 0.5992191433906555 Accuracy : 0.71875\n",
            "Iteration 160 of epoch 3 complete. Loss : 0.5610889196395874 Accuracy : 0.875\n",
            "Iteration 180 of epoch 3 complete. Loss : 0.6118442416191101 Accuracy : 0.6875\n",
            "Iteration 200 of epoch 3 complete. Loss : 0.5722701549530029 Accuracy : 0.75\n",
            "Iteration 220 of epoch 3 complete. Loss : 0.5980112552642822 Accuracy : 0.75\n",
            "Iteration 240 of epoch 3 complete. Loss : 0.5569607019424438 Accuracy : 0.8125\n",
            "Iteration 260 of epoch 3 complete. Loss : 0.6788729429244995 Accuracy : 0.59375\n",
            "Iteration 280 of epoch 3 complete. Loss : 0.6276382803916931 Accuracy : 0.625\n",
            "Iteration 300 of epoch 3 complete. Loss : 0.5791875123977661 Accuracy : 0.71875\n",
            "Iteration 320 of epoch 3 complete. Loss : 0.6136386394500732 Accuracy : 0.71875\n",
            "Iteration 340 of epoch 3 complete. Loss : 0.5623236894607544 Accuracy : 0.75\n",
            "Iteration 360 of epoch 3 complete. Loss : 0.5986193418502808 Accuracy : 0.6875\n",
            "Iteration 380 of epoch 3 complete. Loss : 0.589932918548584 Accuracy : 0.6875\n",
            "Iteration 400 of epoch 3 complete. Loss : 0.626556396484375 Accuracy : 0.6875\n",
            "Iteration 420 of epoch 3 complete. Loss : 0.562369167804718 Accuracy : 0.78125\n",
            "Iteration 440 of epoch 3 complete. Loss : 0.5357370376586914 Accuracy : 0.84375\n",
            "Iteration 460 of epoch 3 complete. Loss : 0.6658341288566589 Accuracy : 0.59375\n",
            "Iteration 480 of epoch 3 complete. Loss : 0.5809792280197144 Accuracy : 0.6875\n",
            "Epoch [3/20], Loss:290.8849\n",
            "Iteration 20 of epoch 4 complete. Loss : 0.6500473618507385 Accuracy : 0.625\n",
            "Iteration 40 of epoch 4 complete. Loss : 0.617911696434021 Accuracy : 0.75\n",
            "Iteration 60 of epoch 4 complete. Loss : 0.6464760303497314 Accuracy : 0.625\n",
            "Iteration 80 of epoch 4 complete. Loss : 0.5382850170135498 Accuracy : 0.78125\n",
            "Iteration 100 of epoch 4 complete. Loss : 0.6495070457458496 Accuracy : 0.59375\n",
            "Iteration 120 of epoch 4 complete. Loss : 0.6297258734703064 Accuracy : 0.625\n",
            "Iteration 140 of epoch 4 complete. Loss : 0.46278315782546997 Accuracy : 0.9375\n",
            "Iteration 160 of epoch 4 complete. Loss : 0.6452676653862 Accuracy : 0.6875\n",
            "Iteration 180 of epoch 4 complete. Loss : 0.5473544597625732 Accuracy : 0.8125\n",
            "Iteration 200 of epoch 4 complete. Loss : 0.6027178168296814 Accuracy : 0.6875\n",
            "Iteration 220 of epoch 4 complete. Loss : 0.4526408612728119 Accuracy : 0.9375\n",
            "Iteration 240 of epoch 4 complete. Loss : 0.5361878275871277 Accuracy : 0.8125\n",
            "Iteration 260 of epoch 4 complete. Loss : 0.6119111776351929 Accuracy : 0.6875\n",
            "Iteration 280 of epoch 4 complete. Loss : 0.5639539361000061 Accuracy : 0.75\n",
            "Iteration 300 of epoch 4 complete. Loss : 0.6177940368652344 Accuracy : 0.65625\n",
            "Iteration 320 of epoch 4 complete. Loss : 0.5294185876846313 Accuracy : 0.8125\n",
            "Iteration 340 of epoch 4 complete. Loss : 0.6393647193908691 Accuracy : 0.65625\n",
            "Iteration 360 of epoch 4 complete. Loss : 0.593307375907898 Accuracy : 0.6875\n",
            "Iteration 380 of epoch 4 complete. Loss : 0.5043799877166748 Accuracy : 0.875\n",
            "Iteration 400 of epoch 4 complete. Loss : 0.5314581394195557 Accuracy : 0.8125\n",
            "Iteration 420 of epoch 4 complete. Loss : 0.40050315856933594 Accuracy : 1.0\n",
            "Iteration 440 of epoch 4 complete. Loss : 0.5122299194335938 Accuracy : 0.8125\n",
            "Iteration 460 of epoch 4 complete. Loss : 0.5048954486846924 Accuracy : 0.875\n",
            "Iteration 480 of epoch 4 complete. Loss : 0.5206950902938843 Accuracy : 0.78125\n",
            "Epoch [4/20], Loss:274.4880\n",
            "Iteration 20 of epoch 5 complete. Loss : 0.4759629964828491 Accuracy : 0.8125\n",
            "Iteration 40 of epoch 5 complete. Loss : 0.48268282413482666 Accuracy : 0.875\n",
            "Iteration 60 of epoch 5 complete. Loss : 0.6162276864051819 Accuracy : 0.625\n",
            "Iteration 80 of epoch 5 complete. Loss : 0.5104256868362427 Accuracy : 0.8125\n",
            "Iteration 100 of epoch 5 complete. Loss : 0.6576833724975586 Accuracy : 0.65625\n",
            "Iteration 120 of epoch 5 complete. Loss : 0.48796385526657104 Accuracy : 0.8125\n",
            "Iteration 140 of epoch 5 complete. Loss : 0.6065800189971924 Accuracy : 0.71875\n",
            "Iteration 160 of epoch 5 complete. Loss : 0.5220499634742737 Accuracy : 0.78125\n",
            "Iteration 180 of epoch 5 complete. Loss : 0.507714033126831 Accuracy : 0.84375\n",
            "Iteration 200 of epoch 5 complete. Loss : 0.5988447666168213 Accuracy : 0.6875\n",
            "Iteration 220 of epoch 5 complete. Loss : 0.5636564493179321 Accuracy : 0.75\n",
            "Iteration 240 of epoch 5 complete. Loss : 0.4673365354537964 Accuracy : 0.875\n",
            "Iteration 260 of epoch 5 complete. Loss : 0.5938369035720825 Accuracy : 0.6875\n",
            "Iteration 280 of epoch 5 complete. Loss : 0.5462696552276611 Accuracy : 0.71875\n",
            "Iteration 300 of epoch 5 complete. Loss : 0.501517653465271 Accuracy : 0.8125\n",
            "Iteration 320 of epoch 5 complete. Loss : 0.5707728862762451 Accuracy : 0.6875\n",
            "Iteration 340 of epoch 5 complete. Loss : 0.602613091468811 Accuracy : 0.65625\n",
            "Iteration 360 of epoch 5 complete. Loss : 0.5541870594024658 Accuracy : 0.71875\n",
            "Iteration 380 of epoch 5 complete. Loss : 0.5468053817749023 Accuracy : 0.78125\n",
            "Iteration 400 of epoch 5 complete. Loss : 0.5273479223251343 Accuracy : 0.78125\n",
            "Iteration 420 of epoch 5 complete. Loss : 0.5475125312805176 Accuracy : 0.75\n",
            "Iteration 440 of epoch 5 complete. Loss : 0.5464074611663818 Accuracy : 0.75\n",
            "Iteration 460 of epoch 5 complete. Loss : 0.507648229598999 Accuracy : 0.78125\n",
            "Iteration 480 of epoch 5 complete. Loss : 0.4923132061958313 Accuracy : 0.84375\n",
            "Epoch [5/20], Loss:263.8791\n",
            "Iteration 20 of epoch 6 complete. Loss : 0.5656063556671143 Accuracy : 0.75\n",
            "Iteration 40 of epoch 6 complete. Loss : 0.5539251565933228 Accuracy : 0.71875\n",
            "Iteration 60 of epoch 6 complete. Loss : 0.5793939828872681 Accuracy : 0.6875\n",
            "Iteration 80 of epoch 6 complete. Loss : 0.5663222074508667 Accuracy : 0.78125\n",
            "Iteration 100 of epoch 6 complete. Loss : 0.5283263921737671 Accuracy : 0.75\n",
            "Iteration 120 of epoch 6 complete. Loss : 0.4433358907699585 Accuracy : 0.90625\n",
            "Iteration 140 of epoch 6 complete. Loss : 0.536922812461853 Accuracy : 0.75\n",
            "Iteration 160 of epoch 6 complete. Loss : 0.52763432264328 Accuracy : 0.75\n",
            "Iteration 180 of epoch 6 complete. Loss : 0.5600785613059998 Accuracy : 0.78125\n",
            "Iteration 200 of epoch 6 complete. Loss : 0.5475044250488281 Accuracy : 0.75\n",
            "Iteration 220 of epoch 6 complete. Loss : 0.5445740818977356 Accuracy : 0.75\n",
            "Iteration 240 of epoch 6 complete. Loss : 0.5403364896774292 Accuracy : 0.71875\n",
            "Iteration 260 of epoch 6 complete. Loss : 0.4932228922843933 Accuracy : 0.78125\n",
            "Iteration 280 of epoch 6 complete. Loss : 0.5833296179771423 Accuracy : 0.71875\n",
            "Iteration 300 of epoch 6 complete. Loss : 0.5371986627578735 Accuracy : 0.75\n",
            "Iteration 320 of epoch 6 complete. Loss : 0.47483426332473755 Accuracy : 0.75\n",
            "Iteration 340 of epoch 6 complete. Loss : 0.4860073924064636 Accuracy : 0.84375\n",
            "Iteration 360 of epoch 6 complete. Loss : 0.5110393166542053 Accuracy : 0.8125\n",
            "Iteration 380 of epoch 6 complete. Loss : 0.4942944049835205 Accuracy : 0.8125\n",
            "Iteration 400 of epoch 6 complete. Loss : 0.4840083718299866 Accuracy : 0.8125\n",
            "Iteration 420 of epoch 6 complete. Loss : 0.4856623411178589 Accuracy : 0.8125\n",
            "Iteration 440 of epoch 6 complete. Loss : 0.5138924717903137 Accuracy : 0.78125\n",
            "Iteration 460 of epoch 6 complete. Loss : 0.5952823162078857 Accuracy : 0.71875\n",
            "Iteration 480 of epoch 6 complete. Loss : 0.466805636882782 Accuracy : 0.875\n",
            "Epoch [6/20], Loss:253.7907\n",
            "Iteration 20 of epoch 7 complete. Loss : 0.5117843747138977 Accuracy : 0.78125\n",
            "Iteration 40 of epoch 7 complete. Loss : 0.42440953850746155 Accuracy : 0.875\n",
            "Iteration 60 of epoch 7 complete. Loss : 0.533700704574585 Accuracy : 0.78125\n",
            "Iteration 80 of epoch 7 complete. Loss : 0.5105262994766235 Accuracy : 0.75\n",
            "Iteration 100 of epoch 7 complete. Loss : 0.3997225761413574 Accuracy : 0.875\n",
            "Iteration 120 of epoch 7 complete. Loss : 0.5347163677215576 Accuracy : 0.71875\n",
            "Iteration 140 of epoch 7 complete. Loss : 0.44635009765625 Accuracy : 0.84375\n",
            "Iteration 160 of epoch 7 complete. Loss : 0.5978556275367737 Accuracy : 0.65625\n",
            "Iteration 180 of epoch 7 complete. Loss : 0.45992374420166016 Accuracy : 0.84375\n",
            "Iteration 200 of epoch 7 complete. Loss : 0.48183417320251465 Accuracy : 0.84375\n",
            "Iteration 220 of epoch 7 complete. Loss : 0.5308108925819397 Accuracy : 0.6875\n",
            "Iteration 240 of epoch 7 complete. Loss : 0.5796207189559937 Accuracy : 0.71875\n",
            "Iteration 260 of epoch 7 complete. Loss : 0.5528112649917603 Accuracy : 0.71875\n",
            "Iteration 280 of epoch 7 complete. Loss : 0.5289316177368164 Accuracy : 0.8125\n",
            "Iteration 300 of epoch 7 complete. Loss : 0.5054402351379395 Accuracy : 0.78125\n",
            "Iteration 320 of epoch 7 complete. Loss : 0.5638213157653809 Accuracy : 0.71875\n",
            "Iteration 340 of epoch 7 complete. Loss : 0.3969119191169739 Accuracy : 0.90625\n",
            "Iteration 360 of epoch 7 complete. Loss : 0.4892336130142212 Accuracy : 0.78125\n",
            "Iteration 380 of epoch 7 complete. Loss : 0.4956789016723633 Accuracy : 0.78125\n",
            "Iteration 400 of epoch 7 complete. Loss : 0.5657581090927124 Accuracy : 0.78125\n",
            "Iteration 420 of epoch 7 complete. Loss : 0.6713546514511108 Accuracy : 0.5625\n",
            "Iteration 440 of epoch 7 complete. Loss : 0.5342692136764526 Accuracy : 0.78125\n",
            "Iteration 460 of epoch 7 complete. Loss : 0.47076189517974854 Accuracy : 0.8125\n",
            "Iteration 480 of epoch 7 complete. Loss : 0.38656288385391235 Accuracy : 0.90625\n",
            "Epoch [7/20], Loss:244.6705\n",
            "Iteration 20 of epoch 8 complete. Loss : 0.4368913769721985 Accuracy : 0.84375\n",
            "Iteration 40 of epoch 8 complete. Loss : 0.48097530007362366 Accuracy : 0.78125\n",
            "Iteration 60 of epoch 8 complete. Loss : 0.5021349191665649 Accuracy : 0.8125\n",
            "Iteration 80 of epoch 8 complete. Loss : 0.4545705020427704 Accuracy : 0.84375\n",
            "Iteration 100 of epoch 8 complete. Loss : 0.4215940833091736 Accuracy : 0.90625\n",
            "Iteration 120 of epoch 8 complete. Loss : 0.5191801190376282 Accuracy : 0.75\n",
            "Iteration 140 of epoch 8 complete. Loss : 0.516977071762085 Accuracy : 0.78125\n",
            "Iteration 160 of epoch 8 complete. Loss : 0.6222261190414429 Accuracy : 0.65625\n",
            "Iteration 180 of epoch 8 complete. Loss : 0.3955285847187042 Accuracy : 0.90625\n",
            "Iteration 200 of epoch 8 complete. Loss : 0.5416295528411865 Accuracy : 0.71875\n",
            "Iteration 220 of epoch 8 complete. Loss : 0.4993477463722229 Accuracy : 0.75\n",
            "Iteration 240 of epoch 8 complete. Loss : 0.4038825035095215 Accuracy : 0.84375\n",
            "Iteration 260 of epoch 8 complete. Loss : 0.4994029402732849 Accuracy : 0.78125\n",
            "Iteration 280 of epoch 8 complete. Loss : 0.46150654554367065 Accuracy : 0.84375\n",
            "Iteration 300 of epoch 8 complete. Loss : 0.49514681100845337 Accuracy : 0.75\n",
            "Iteration 320 of epoch 8 complete. Loss : 0.4429229497909546 Accuracy : 0.84375\n",
            "Iteration 340 of epoch 8 complete. Loss : 0.4828605353832245 Accuracy : 0.78125\n",
            "Iteration 360 of epoch 8 complete. Loss : 0.3971603512763977 Accuracy : 0.9375\n",
            "Iteration 380 of epoch 8 complete. Loss : 0.42667028307914734 Accuracy : 0.875\n",
            "Iteration 400 of epoch 8 complete. Loss : 0.4037458896636963 Accuracy : 0.84375\n",
            "Iteration 420 of epoch 8 complete. Loss : 0.5251811146736145 Accuracy : 0.75\n",
            "Iteration 440 of epoch 8 complete. Loss : 0.5498203039169312 Accuracy : 0.6875\n",
            "Iteration 460 of epoch 8 complete. Loss : 0.33598804473876953 Accuracy : 0.96875\n",
            "Iteration 480 of epoch 8 complete. Loss : 0.5657610893249512 Accuracy : 0.6875\n",
            "Epoch [8/20], Loss:236.0576\n",
            "Iteration 20 of epoch 9 complete. Loss : 0.4281606376171112 Accuracy : 0.84375\n",
            "Iteration 40 of epoch 9 complete. Loss : 0.3765115439891815 Accuracy : 0.90625\n",
            "Iteration 60 of epoch 9 complete. Loss : 0.5084516406059265 Accuracy : 0.78125\n",
            "Iteration 80 of epoch 9 complete. Loss : 0.5360747575759888 Accuracy : 0.75\n",
            "Iteration 100 of epoch 9 complete. Loss : 0.4871312379837036 Accuracy : 0.84375\n",
            "Iteration 120 of epoch 9 complete. Loss : 0.5208426713943481 Accuracy : 0.75\n",
            "Iteration 140 of epoch 9 complete. Loss : 0.47671911120414734 Accuracy : 0.8125\n",
            "Iteration 160 of epoch 9 complete. Loss : 0.44469794631004333 Accuracy : 0.84375\n",
            "Iteration 180 of epoch 9 complete. Loss : 0.5088591575622559 Accuracy : 0.8125\n",
            "Iteration 200 of epoch 9 complete. Loss : 0.42903345823287964 Accuracy : 0.75\n",
            "Iteration 220 of epoch 9 complete. Loss : 0.5344691276550293 Accuracy : 0.71875\n",
            "Iteration 240 of epoch 9 complete. Loss : 0.4076235592365265 Accuracy : 0.8125\n",
            "Iteration 260 of epoch 9 complete. Loss : 0.5538116097450256 Accuracy : 0.6875\n",
            "Iteration 280 of epoch 9 complete. Loss : 0.4235832095146179 Accuracy : 0.875\n",
            "Iteration 300 of epoch 9 complete. Loss : 0.4801742434501648 Accuracy : 0.8125\n",
            "Iteration 320 of epoch 9 complete. Loss : 0.40867385268211365 Accuracy : 0.84375\n",
            "Iteration 340 of epoch 9 complete. Loss : 0.380307674407959 Accuracy : 0.875\n",
            "Iteration 360 of epoch 9 complete. Loss : 0.42216241359710693 Accuracy : 0.875\n",
            "Iteration 380 of epoch 9 complete. Loss : 0.46480196714401245 Accuracy : 0.78125\n",
            "Iteration 400 of epoch 9 complete. Loss : 0.5221524238586426 Accuracy : 0.78125\n",
            "Iteration 420 of epoch 9 complete. Loss : 0.42064642906188965 Accuracy : 0.875\n",
            "Iteration 440 of epoch 9 complete. Loss : 0.5278998017311096 Accuracy : 0.75\n",
            "Iteration 460 of epoch 9 complete. Loss : 0.40535813570022583 Accuracy : 0.875\n",
            "Iteration 480 of epoch 9 complete. Loss : 0.4548030495643616 Accuracy : 0.78125\n",
            "Epoch [9/20], Loss:227.8343\n",
            "Iteration 20 of epoch 10 complete. Loss : 0.5111924409866333 Accuracy : 0.78125\n",
            "Iteration 40 of epoch 10 complete. Loss : 0.46615666151046753 Accuracy : 0.8125\n",
            "Iteration 60 of epoch 10 complete. Loss : 0.3712906241416931 Accuracy : 0.875\n",
            "Iteration 80 of epoch 10 complete. Loss : 0.406787246465683 Accuracy : 0.8125\n",
            "Iteration 100 of epoch 10 complete. Loss : 0.4390859603881836 Accuracy : 0.84375\n",
            "Iteration 120 of epoch 10 complete. Loss : 0.3745712637901306 Accuracy : 0.90625\n",
            "Iteration 140 of epoch 10 complete. Loss : 0.4847874045372009 Accuracy : 0.78125\n",
            "Iteration 160 of epoch 10 complete. Loss : 0.44141316413879395 Accuracy : 0.84375\n",
            "Iteration 180 of epoch 10 complete. Loss : 0.41217565536499023 Accuracy : 0.875\n",
            "Iteration 200 of epoch 10 complete. Loss : 0.4916267693042755 Accuracy : 0.8125\n",
            "Iteration 220 of epoch 10 complete. Loss : 0.44819176197052 Accuracy : 0.8125\n",
            "Iteration 240 of epoch 10 complete. Loss : 0.5167546272277832 Accuracy : 0.78125\n",
            "Iteration 260 of epoch 10 complete. Loss : 0.49521684646606445 Accuracy : 0.75\n",
            "Iteration 280 of epoch 10 complete. Loss : 0.39464908838272095 Accuracy : 0.8125\n",
            "Iteration 300 of epoch 10 complete. Loss : 0.5219631195068359 Accuracy : 0.78125\n",
            "Iteration 320 of epoch 10 complete. Loss : 0.45168566703796387 Accuracy : 0.78125\n",
            "Iteration 340 of epoch 10 complete. Loss : 0.5706567764282227 Accuracy : 0.6875\n",
            "Iteration 360 of epoch 10 complete. Loss : 0.40192681550979614 Accuracy : 0.875\n",
            "Iteration 380 of epoch 10 complete. Loss : 0.48431727290153503 Accuracy : 0.75\n",
            "Iteration 400 of epoch 10 complete. Loss : 0.4647826552391052 Accuracy : 0.84375\n",
            "Iteration 420 of epoch 10 complete. Loss : 0.40793395042419434 Accuracy : 0.84375\n",
            "Iteration 440 of epoch 10 complete. Loss : 0.38168203830718994 Accuracy : 0.84375\n",
            "Iteration 460 of epoch 10 complete. Loss : 0.43134135007858276 Accuracy : 0.84375\n",
            "Iteration 480 of epoch 10 complete. Loss : 0.39285293221473694 Accuracy : 0.90625\n",
            "Epoch [10/20], Loss:220.2978\n",
            "Iteration 20 of epoch 11 complete. Loss : 0.39164501428604126 Accuracy : 0.875\n",
            "Iteration 40 of epoch 11 complete. Loss : 0.5011175870895386 Accuracy : 0.75\n",
            "Iteration 60 of epoch 11 complete. Loss : 0.6223124265670776 Accuracy : 0.6875\n",
            "Iteration 80 of epoch 11 complete. Loss : 0.41875600814819336 Accuracy : 0.8125\n",
            "Iteration 100 of epoch 11 complete. Loss : 0.44434165954589844 Accuracy : 0.84375\n",
            "Iteration 120 of epoch 11 complete. Loss : 0.47016653418540955 Accuracy : 0.84375\n",
            "Iteration 140 of epoch 11 complete. Loss : 0.4714679718017578 Accuracy : 0.78125\n",
            "Iteration 160 of epoch 11 complete. Loss : 0.39654356241226196 Accuracy : 0.875\n",
            "Iteration 180 of epoch 11 complete. Loss : 0.43496212363243103 Accuracy : 0.84375\n",
            "Iteration 200 of epoch 11 complete. Loss : 0.4261804223060608 Accuracy : 0.8125\n",
            "Iteration 220 of epoch 11 complete. Loss : 0.4160330295562744 Accuracy : 0.875\n",
            "Iteration 240 of epoch 11 complete. Loss : 0.5566422939300537 Accuracy : 0.75\n",
            "Iteration 260 of epoch 11 complete. Loss : 0.41271406412124634 Accuracy : 0.8125\n",
            "Iteration 280 of epoch 11 complete. Loss : 0.38105183839797974 Accuracy : 0.875\n",
            "Iteration 300 of epoch 11 complete. Loss : 0.38892289996147156 Accuracy : 0.90625\n",
            "Iteration 320 of epoch 11 complete. Loss : 0.3876555562019348 Accuracy : 0.875\n",
            "Iteration 340 of epoch 11 complete. Loss : 0.42863285541534424 Accuracy : 0.84375\n",
            "Iteration 360 of epoch 11 complete. Loss : 0.36169883608818054 Accuracy : 0.90625\n",
            "Iteration 380 of epoch 11 complete. Loss : 0.5107624530792236 Accuracy : 0.78125\n",
            "Iteration 400 of epoch 11 complete. Loss : 0.42194148898124695 Accuracy : 0.875\n",
            "Iteration 420 of epoch 11 complete. Loss : 0.4347667694091797 Accuracy : 0.8125\n",
            "Iteration 440 of epoch 11 complete. Loss : 0.39509856700897217 Accuracy : 0.875\n",
            "Iteration 460 of epoch 11 complete. Loss : 0.35077959299087524 Accuracy : 0.875\n",
            "Iteration 480 of epoch 11 complete. Loss : 0.41958120465278625 Accuracy : 0.8125\n",
            "Epoch [11/20], Loss:212.0668\n",
            "Iteration 20 of epoch 12 complete. Loss : 0.47931140661239624 Accuracy : 0.8125\n",
            "Iteration 40 of epoch 12 complete. Loss : 0.4817028343677521 Accuracy : 0.78125\n",
            "Iteration 60 of epoch 12 complete. Loss : 0.3707568049430847 Accuracy : 0.875\n",
            "Iteration 80 of epoch 12 complete. Loss : 0.41965144872665405 Accuracy : 0.8125\n",
            "Iteration 100 of epoch 12 complete. Loss : 0.3862186372280121 Accuracy : 0.84375\n",
            "Iteration 120 of epoch 12 complete. Loss : 0.32297274470329285 Accuracy : 0.90625\n",
            "Iteration 140 of epoch 12 complete. Loss : 0.4546058177947998 Accuracy : 0.8125\n",
            "Iteration 160 of epoch 12 complete. Loss : 0.31557828187942505 Accuracy : 0.90625\n",
            "Iteration 180 of epoch 12 complete. Loss : 0.3773011267185211 Accuracy : 0.875\n",
            "Iteration 200 of epoch 12 complete. Loss : 0.37972405552864075 Accuracy : 0.875\n",
            "Iteration 220 of epoch 12 complete. Loss : 0.36076873540878296 Accuracy : 0.90625\n",
            "Iteration 240 of epoch 12 complete. Loss : 0.32798537611961365 Accuracy : 0.90625\n",
            "Iteration 260 of epoch 12 complete. Loss : 0.3905121088027954 Accuracy : 0.84375\n",
            "Iteration 280 of epoch 12 complete. Loss : 0.3858643174171448 Accuracy : 0.90625\n",
            "Iteration 300 of epoch 12 complete. Loss : 0.4996274411678314 Accuracy : 0.8125\n",
            "Iteration 320 of epoch 12 complete. Loss : 0.4052596092224121 Accuracy : 0.78125\n",
            "Iteration 340 of epoch 12 complete. Loss : 0.4324992299079895 Accuracy : 0.8125\n",
            "Iteration 360 of epoch 12 complete. Loss : 0.3928467631340027 Accuracy : 0.875\n",
            "Iteration 380 of epoch 12 complete. Loss : 0.42365938425064087 Accuracy : 0.8125\n",
            "Iteration 400 of epoch 12 complete. Loss : 0.5945214033126831 Accuracy : 0.71875\n",
            "Iteration 420 of epoch 12 complete. Loss : 0.3660067319869995 Accuracy : 0.875\n",
            "Iteration 440 of epoch 12 complete. Loss : 0.5629808902740479 Accuracy : 0.65625\n",
            "Iteration 460 of epoch 12 complete. Loss : 0.4243431091308594 Accuracy : 0.8125\n",
            "Iteration 480 of epoch 12 complete. Loss : 0.2946281433105469 Accuracy : 0.90625\n",
            "Epoch [12/20], Loss:204.8218\n",
            "Iteration 20 of epoch 13 complete. Loss : 0.3425624370574951 Accuracy : 0.84375\n",
            "Iteration 40 of epoch 13 complete. Loss : 0.5045750141143799 Accuracy : 0.71875\n",
            "Iteration 60 of epoch 13 complete. Loss : 0.45489293336868286 Accuracy : 0.8125\n",
            "Iteration 80 of epoch 13 complete. Loss : 0.3247356712818146 Accuracy : 0.90625\n",
            "Iteration 100 of epoch 13 complete. Loss : 0.5038926005363464 Accuracy : 0.78125\n",
            "Iteration 120 of epoch 13 complete. Loss : 0.5564892292022705 Accuracy : 0.71875\n",
            "Iteration 140 of epoch 13 complete. Loss : 0.3748948276042938 Accuracy : 0.875\n",
            "Iteration 160 of epoch 13 complete. Loss : 0.3804585933685303 Accuracy : 0.875\n",
            "Iteration 180 of epoch 13 complete. Loss : 0.5476053953170776 Accuracy : 0.75\n",
            "Iteration 200 of epoch 13 complete. Loss : 0.41334226727485657 Accuracy : 0.8125\n",
            "Iteration 220 of epoch 13 complete. Loss : 0.3636239767074585 Accuracy : 0.875\n",
            "Iteration 240 of epoch 13 complete. Loss : 0.47888728976249695 Accuracy : 0.84375\n",
            "Iteration 260 of epoch 13 complete. Loss : 0.4204140901565552 Accuracy : 0.84375\n",
            "Iteration 280 of epoch 13 complete. Loss : 0.443196177482605 Accuracy : 0.78125\n",
            "Iteration 300 of epoch 13 complete. Loss : 0.3087085485458374 Accuracy : 0.90625\n",
            "Iteration 320 of epoch 13 complete. Loss : 0.2729179859161377 Accuracy : 0.9375\n",
            "Iteration 340 of epoch 13 complete. Loss : 0.39434492588043213 Accuracy : 0.875\n",
            "Iteration 360 of epoch 13 complete. Loss : 0.43468111753463745 Accuracy : 0.8125\n",
            "Iteration 380 of epoch 13 complete. Loss : 0.4590374231338501 Accuracy : 0.78125\n",
            "Iteration 400 of epoch 13 complete. Loss : 0.3583691418170929 Accuracy : 0.875\n",
            "Iteration 420 of epoch 13 complete. Loss : 0.47433942556381226 Accuracy : 0.8125\n",
            "Iteration 440 of epoch 13 complete. Loss : 0.43586474657058716 Accuracy : 0.8125\n",
            "Iteration 460 of epoch 13 complete. Loss : 0.3980477452278137 Accuracy : 0.84375\n",
            "Iteration 480 of epoch 13 complete. Loss : 0.49589890241622925 Accuracy : 0.75\n",
            "Epoch [13/20], Loss:198.3478\n",
            "Iteration 20 of epoch 14 complete. Loss : 0.3184233605861664 Accuracy : 0.9375\n",
            "Iteration 40 of epoch 14 complete. Loss : 0.3639882206916809 Accuracy : 0.84375\n",
            "Iteration 60 of epoch 14 complete. Loss : 0.3863591253757477 Accuracy : 0.78125\n",
            "Iteration 80 of epoch 14 complete. Loss : 0.31859228014945984 Accuracy : 0.90625\n",
            "Iteration 100 of epoch 14 complete. Loss : 0.3615061342716217 Accuracy : 0.875\n",
            "Iteration 120 of epoch 14 complete. Loss : 0.47744086384773254 Accuracy : 0.8125\n",
            "Iteration 140 of epoch 14 complete. Loss : 0.5019744634628296 Accuracy : 0.75\n",
            "Iteration 160 of epoch 14 complete. Loss : 0.40355539321899414 Accuracy : 0.875\n",
            "Iteration 180 of epoch 14 complete. Loss : 0.3825712203979492 Accuracy : 0.84375\n",
            "Iteration 200 of epoch 14 complete. Loss : 0.4271828830242157 Accuracy : 0.84375\n",
            "Iteration 220 of epoch 14 complete. Loss : 0.4999997317790985 Accuracy : 0.78125\n",
            "Iteration 240 of epoch 14 complete. Loss : 0.452811062335968 Accuracy : 0.75\n",
            "Iteration 260 of epoch 14 complete. Loss : 0.4691724479198456 Accuracy : 0.75\n",
            "Iteration 280 of epoch 14 complete. Loss : 0.3542103171348572 Accuracy : 0.875\n",
            "Iteration 300 of epoch 14 complete. Loss : 0.31198763847351074 Accuracy : 0.90625\n",
            "Iteration 320 of epoch 14 complete. Loss : 0.5268570184707642 Accuracy : 0.75\n",
            "Iteration 340 of epoch 14 complete. Loss : 0.3946390748023987 Accuracy : 0.875\n",
            "Iteration 360 of epoch 14 complete. Loss : 0.21623124182224274 Accuracy : 0.96875\n",
            "Iteration 380 of epoch 14 complete. Loss : 0.48920226097106934 Accuracy : 0.75\n",
            "Iteration 400 of epoch 14 complete. Loss : 0.2197209894657135 Accuracy : 0.96875\n",
            "Iteration 420 of epoch 14 complete. Loss : 0.38368743658065796 Accuracy : 0.84375\n",
            "Iteration 440 of epoch 14 complete. Loss : 0.39393219351768494 Accuracy : 0.875\n",
            "Iteration 460 of epoch 14 complete. Loss : 0.3804593086242676 Accuracy : 0.84375\n",
            "Iteration 480 of epoch 14 complete. Loss : 0.3947629928588867 Accuracy : 0.875\n",
            "Epoch [14/20], Loss:193.2308\n",
            "Iteration 20 of epoch 15 complete. Loss : 0.3397839069366455 Accuracy : 0.875\n",
            "Iteration 40 of epoch 15 complete. Loss : 0.28082558512687683 Accuracy : 0.9375\n",
            "Iteration 60 of epoch 15 complete. Loss : 0.26626843214035034 Accuracy : 0.96875\n",
            "Iteration 80 of epoch 15 complete. Loss : 0.34577426314353943 Accuracy : 0.84375\n",
            "Iteration 100 of epoch 15 complete. Loss : 0.4605610966682434 Accuracy : 0.78125\n",
            "Iteration 120 of epoch 15 complete. Loss : 0.35401204228401184 Accuracy : 0.875\n",
            "Iteration 140 of epoch 15 complete. Loss : 0.35344576835632324 Accuracy : 0.875\n",
            "Iteration 160 of epoch 15 complete. Loss : 0.40445926785469055 Accuracy : 0.84375\n",
            "Iteration 180 of epoch 15 complete. Loss : 0.3751797676086426 Accuracy : 0.84375\n",
            "Iteration 200 of epoch 15 complete. Loss : 0.33178412914276123 Accuracy : 0.875\n",
            "Iteration 220 of epoch 15 complete. Loss : 0.41549521684646606 Accuracy : 0.8125\n",
            "Iteration 240 of epoch 15 complete. Loss : 0.4808160662651062 Accuracy : 0.75\n",
            "Iteration 260 of epoch 15 complete. Loss : 0.4401107430458069 Accuracy : 0.8125\n",
            "Iteration 280 of epoch 15 complete. Loss : 0.24148023128509521 Accuracy : 0.9375\n",
            "Iteration 300 of epoch 15 complete. Loss : 0.3055931031703949 Accuracy : 0.90625\n",
            "Iteration 320 of epoch 15 complete. Loss : 0.44100305438041687 Accuracy : 0.84375\n",
            "Iteration 340 of epoch 15 complete. Loss : 0.30781710147857666 Accuracy : 0.90625\n",
            "Iteration 360 of epoch 15 complete. Loss : 0.4415438175201416 Accuracy : 0.8125\n",
            "Iteration 380 of epoch 15 complete. Loss : 0.5412387251853943 Accuracy : 0.71875\n",
            "Iteration 400 of epoch 15 complete. Loss : 0.5097625255584717 Accuracy : 0.78125\n",
            "Iteration 420 of epoch 15 complete. Loss : 0.3324449360370636 Accuracy : 0.90625\n",
            "Iteration 440 of epoch 15 complete. Loss : 0.39660537242889404 Accuracy : 0.84375\n",
            "Iteration 460 of epoch 15 complete. Loss : 0.3051188886165619 Accuracy : 0.875\n",
            "Iteration 480 of epoch 15 complete. Loss : 0.37301012873649597 Accuracy : 0.8125\n",
            "Epoch [15/20], Loss:187.1250\n",
            "Iteration 20 of epoch 16 complete. Loss : 0.4724103510379791 Accuracy : 0.78125\n",
            "Iteration 40 of epoch 16 complete. Loss : 0.38738107681274414 Accuracy : 0.84375\n",
            "Iteration 60 of epoch 16 complete. Loss : 0.4064987897872925 Accuracy : 0.8125\n",
            "Iteration 80 of epoch 16 complete. Loss : 0.36744552850723267 Accuracy : 0.8125\n",
            "Iteration 100 of epoch 16 complete. Loss : 0.4867069125175476 Accuracy : 0.75\n",
            "Iteration 120 of epoch 16 complete. Loss : 0.3036283850669861 Accuracy : 0.9375\n",
            "Iteration 140 of epoch 16 complete. Loss : 0.35001617670059204 Accuracy : 0.875\n",
            "Iteration 160 of epoch 16 complete. Loss : 0.3582358658313751 Accuracy : 0.84375\n",
            "Iteration 180 of epoch 16 complete. Loss : 0.3590397238731384 Accuracy : 0.875\n",
            "Iteration 200 of epoch 16 complete. Loss : 0.35889697074890137 Accuracy : 0.84375\n",
            "Iteration 220 of epoch 16 complete. Loss : 0.544019341468811 Accuracy : 0.71875\n",
            "Iteration 240 of epoch 16 complete. Loss : 0.28669190406799316 Accuracy : 0.90625\n",
            "Iteration 260 of epoch 16 complete. Loss : 0.3817325234413147 Accuracy : 0.78125\n",
            "Iteration 280 of epoch 16 complete. Loss : 0.4495036005973816 Accuracy : 0.78125\n",
            "Iteration 300 of epoch 16 complete. Loss : 0.540198028087616 Accuracy : 0.65625\n",
            "Iteration 320 of epoch 16 complete. Loss : 0.3273729979991913 Accuracy : 0.875\n",
            "Iteration 340 of epoch 16 complete. Loss : 0.5289911031723022 Accuracy : 0.71875\n",
            "Iteration 360 of epoch 16 complete. Loss : 0.39985793828964233 Accuracy : 0.84375\n",
            "Iteration 380 of epoch 16 complete. Loss : 0.2799164652824402 Accuracy : 0.90625\n",
            "Iteration 400 of epoch 16 complete. Loss : 0.3509066700935364 Accuracy : 0.875\n",
            "Iteration 420 of epoch 16 complete. Loss : 0.41682159900665283 Accuracy : 0.84375\n",
            "Iteration 440 of epoch 16 complete. Loss : 0.3821741044521332 Accuracy : 0.84375\n",
            "Iteration 460 of epoch 16 complete. Loss : 0.3211882710456848 Accuracy : 0.90625\n",
            "Iteration 480 of epoch 16 complete. Loss : 0.43376511335372925 Accuracy : 0.78125\n",
            "Epoch [16/20], Loss:181.5016\n",
            "Iteration 20 of epoch 17 complete. Loss : 0.29287999868392944 Accuracy : 0.90625\n",
            "Iteration 40 of epoch 17 complete. Loss : 0.3780006170272827 Accuracy : 0.875\n",
            "Iteration 60 of epoch 17 complete. Loss : 0.5003104209899902 Accuracy : 0.78125\n",
            "Iteration 80 of epoch 17 complete. Loss : 0.3882877826690674 Accuracy : 0.90625\n",
            "Iteration 100 of epoch 17 complete. Loss : 0.437502920627594 Accuracy : 0.8125\n",
            "Iteration 120 of epoch 17 complete. Loss : 0.39217180013656616 Accuracy : 0.875\n",
            "Iteration 140 of epoch 17 complete. Loss : 0.36508142948150635 Accuracy : 0.875\n",
            "Iteration 160 of epoch 17 complete. Loss : 0.398356169462204 Accuracy : 0.84375\n",
            "Iteration 180 of epoch 17 complete. Loss : 0.3972160816192627 Accuracy : 0.875\n",
            "Iteration 200 of epoch 17 complete. Loss : 0.3102668225765228 Accuracy : 0.90625\n",
            "Iteration 220 of epoch 17 complete. Loss : 0.5210102796554565 Accuracy : 0.6875\n",
            "Iteration 240 of epoch 17 complete. Loss : 0.36747708916664124 Accuracy : 0.84375\n",
            "Iteration 260 of epoch 17 complete. Loss : 0.419017493724823 Accuracy : 0.8125\n",
            "Iteration 280 of epoch 17 complete. Loss : 0.43601495027542114 Accuracy : 0.8125\n",
            "Iteration 300 of epoch 17 complete. Loss : 0.4720801115036011 Accuracy : 0.75\n",
            "Iteration 320 of epoch 17 complete. Loss : 0.3253418803215027 Accuracy : 0.90625\n",
            "Iteration 340 of epoch 17 complete. Loss : 0.5460181832313538 Accuracy : 0.75\n",
            "Iteration 360 of epoch 17 complete. Loss : 0.4770966172218323 Accuracy : 0.75\n",
            "Iteration 380 of epoch 17 complete. Loss : 0.2752031087875366 Accuracy : 0.9375\n",
            "Iteration 400 of epoch 17 complete. Loss : 0.3947973847389221 Accuracy : 0.8125\n",
            "Iteration 420 of epoch 17 complete. Loss : 0.2897331714630127 Accuracy : 0.90625\n",
            "Iteration 440 of epoch 17 complete. Loss : 0.3077346682548523 Accuracy : 0.9375\n",
            "Iteration 460 of epoch 17 complete. Loss : 0.4326460361480713 Accuracy : 0.78125\n",
            "Iteration 480 of epoch 17 complete. Loss : 0.3504592776298523 Accuracy : 0.84375\n",
            "Epoch [17/20], Loss:177.0774\n",
            "Iteration 20 of epoch 18 complete. Loss : 0.3079272210597992 Accuracy : 0.875\n",
            "Iteration 40 of epoch 18 complete. Loss : 0.4589366912841797 Accuracy : 0.71875\n",
            "Iteration 60 of epoch 18 complete. Loss : 0.3109913468360901 Accuracy : 0.90625\n",
            "Iteration 80 of epoch 18 complete. Loss : 0.4002598524093628 Accuracy : 0.84375\n",
            "Iteration 100 of epoch 18 complete. Loss : 0.3727039694786072 Accuracy : 0.84375\n",
            "Iteration 120 of epoch 18 complete. Loss : 0.3508604168891907 Accuracy : 0.875\n",
            "Iteration 140 of epoch 18 complete. Loss : 0.35702794790267944 Accuracy : 0.90625\n",
            "Iteration 160 of epoch 18 complete. Loss : 0.4281350374221802 Accuracy : 0.8125\n",
            "Iteration 180 of epoch 18 complete. Loss : 0.4030572772026062 Accuracy : 0.84375\n",
            "Iteration 200 of epoch 18 complete. Loss : 0.38140493631362915 Accuracy : 0.875\n",
            "Iteration 220 of epoch 18 complete. Loss : 0.4461521506309509 Accuracy : 0.8125\n",
            "Iteration 240 of epoch 18 complete. Loss : 0.4178124964237213 Accuracy : 0.84375\n",
            "Iteration 260 of epoch 18 complete. Loss : 0.3585773706436157 Accuracy : 0.875\n",
            "Iteration 280 of epoch 18 complete. Loss : 0.3341875374317169 Accuracy : 0.875\n",
            "Iteration 300 of epoch 18 complete. Loss : 0.3638070821762085 Accuracy : 0.875\n",
            "Iteration 320 of epoch 18 complete. Loss : 0.37428027391433716 Accuracy : 0.84375\n",
            "Iteration 340 of epoch 18 complete. Loss : 0.25895148515701294 Accuracy : 0.9375\n",
            "Iteration 360 of epoch 18 complete. Loss : 0.44929540157318115 Accuracy : 0.78125\n",
            "Iteration 380 of epoch 18 complete. Loss : 0.35053592920303345 Accuracy : 0.84375\n",
            "Iteration 400 of epoch 18 complete. Loss : 0.18147526681423187 Accuracy : 0.96875\n",
            "Iteration 420 of epoch 18 complete. Loss : 0.452282577753067 Accuracy : 0.75\n",
            "Iteration 440 of epoch 18 complete. Loss : 0.239127516746521 Accuracy : 0.9375\n",
            "Iteration 460 of epoch 18 complete. Loss : 0.30972641706466675 Accuracy : 0.9375\n",
            "Iteration 480 of epoch 18 complete. Loss : 0.35205405950546265 Accuracy : 0.84375\n",
            "Epoch [18/20], Loss:171.5453\n",
            "Iteration 20 of epoch 19 complete. Loss : 0.24162490665912628 Accuracy : 0.90625\n",
            "Iteration 40 of epoch 19 complete. Loss : 0.44756370782852173 Accuracy : 0.8125\n",
            "Iteration 60 of epoch 19 complete. Loss : 0.3398746848106384 Accuracy : 0.84375\n",
            "Iteration 80 of epoch 19 complete. Loss : 0.38976144790649414 Accuracy : 0.84375\n",
            "Iteration 100 of epoch 19 complete. Loss : 0.38054338097572327 Accuracy : 0.75\n",
            "Iteration 120 of epoch 19 complete. Loss : 0.516924262046814 Accuracy : 0.78125\n",
            "Iteration 140 of epoch 19 complete. Loss : 0.370501846075058 Accuracy : 0.875\n",
            "Iteration 160 of epoch 19 complete. Loss : 0.4028463363647461 Accuracy : 0.8125\n",
            "Iteration 180 of epoch 19 complete. Loss : 0.4466484785079956 Accuracy : 0.8125\n",
            "Iteration 200 of epoch 19 complete. Loss : 0.28700685501098633 Accuracy : 0.84375\n",
            "Iteration 220 of epoch 19 complete. Loss : 0.2436097264289856 Accuracy : 0.9375\n",
            "Iteration 240 of epoch 19 complete. Loss : 0.26167601346969604 Accuracy : 0.90625\n",
            "Iteration 260 of epoch 19 complete. Loss : 0.4338253140449524 Accuracy : 0.8125\n",
            "Iteration 280 of epoch 19 complete. Loss : 0.3682381808757782 Accuracy : 0.875\n",
            "Iteration 300 of epoch 19 complete. Loss : 0.40919920802116394 Accuracy : 0.8125\n",
            "Iteration 320 of epoch 19 complete. Loss : 0.25850751996040344 Accuracy : 0.9375\n",
            "Iteration 340 of epoch 19 complete. Loss : 0.32437628507614136 Accuracy : 0.84375\n",
            "Iteration 360 of epoch 19 complete. Loss : 0.19963496923446655 Accuracy : 0.9375\n",
            "Iteration 380 of epoch 19 complete. Loss : 0.46009817719459534 Accuracy : 0.75\n",
            "Iteration 400 of epoch 19 complete. Loss : 0.19666656851768494 Accuracy : 0.96875\n",
            "Iteration 420 of epoch 19 complete. Loss : 0.3218042850494385 Accuracy : 0.84375\n",
            "Iteration 440 of epoch 19 complete. Loss : 0.27497726678848267 Accuracy : 0.90625\n",
            "Iteration 460 of epoch 19 complete. Loss : 0.31864461302757263 Accuracy : 0.90625\n",
            "Iteration 480 of epoch 19 complete. Loss : 0.33276113867759705 Accuracy : 0.90625\n",
            "Epoch [19/20], Loss:166.3645\n",
            "Iteration 20 of epoch 20 complete. Loss : 0.46256211400032043 Accuracy : 0.8125\n",
            "Iteration 40 of epoch 20 complete. Loss : 0.274877667427063 Accuracy : 0.9375\n",
            "Iteration 60 of epoch 20 complete. Loss : 0.347993403673172 Accuracy : 0.875\n",
            "Iteration 80 of epoch 20 complete. Loss : 0.2582152485847473 Accuracy : 0.90625\n",
            "Iteration 100 of epoch 20 complete. Loss : 0.31110435724258423 Accuracy : 0.875\n",
            "Iteration 120 of epoch 20 complete. Loss : 0.28518617153167725 Accuracy : 0.875\n",
            "Iteration 140 of epoch 20 complete. Loss : 0.3626522421836853 Accuracy : 0.90625\n",
            "Iteration 160 of epoch 20 complete. Loss : 0.24860212206840515 Accuracy : 0.90625\n",
            "Iteration 180 of epoch 20 complete. Loss : 0.25824204087257385 Accuracy : 0.9375\n",
            "Iteration 200 of epoch 20 complete. Loss : 0.30771753191947937 Accuracy : 0.875\n",
            "Iteration 220 of epoch 20 complete. Loss : 0.4685571491718292 Accuracy : 0.78125\n",
            "Iteration 240 of epoch 20 complete. Loss : 0.24877780675888062 Accuracy : 0.90625\n",
            "Iteration 260 of epoch 20 complete. Loss : 0.2815394401550293 Accuracy : 0.90625\n",
            "Iteration 280 of epoch 20 complete. Loss : 0.30936723947525024 Accuracy : 0.875\n",
            "Iteration 300 of epoch 20 complete. Loss : 0.2639823257923126 Accuracy : 0.90625\n",
            "Iteration 320 of epoch 20 complete. Loss : 0.2957804203033447 Accuracy : 0.875\n",
            "Iteration 340 of epoch 20 complete. Loss : 0.2652297616004944 Accuracy : 0.9375\n",
            "Iteration 360 of epoch 20 complete. Loss : 0.30244702100753784 Accuracy : 0.90625\n",
            "Iteration 380 of epoch 20 complete. Loss : 0.3043079972267151 Accuracy : 0.875\n",
            "Iteration 400 of epoch 20 complete. Loss : 0.25010085105895996 Accuracy : 0.90625\n",
            "Iteration 420 of epoch 20 complete. Loss : 0.38969486951828003 Accuracy : 0.84375\n",
            "Iteration 440 of epoch 20 complete. Loss : 0.34971481561660767 Accuracy : 0.8125\n",
            "Iteration 460 of epoch 20 complete. Loss : 0.4133533835411072 Accuracy : 0.78125\n",
            "Iteration 480 of epoch 20 complete. Loss : 0.31769508123397827 Accuracy : 0.84375\n",
            "Epoch [20/20], Loss:161.0939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCNYTArxQ74N"
      },
      "source": [
        "def get_labels_from_logits(logits) :\n",
        "  probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "  soft_probs = (probs > 0.5).long()\n",
        "  labels = soft_probs.squeeze()\n",
        "  return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HkxYM_tpWlJ"
      },
      "source": [
        "def eval_model(model, val_loader) :\n",
        "  final_out = []\n",
        "  final_lab = []\n",
        "\n",
        "  for idx, (val_input, val_mask,val_label) in enumerate(val_loader):\n",
        "    try:\n",
        "      val_input = val_input.cuda()\n",
        "      val_mask = val_mask.cuda()\n",
        "      output = model(val_input, val_mask)\n",
        "      output = get_labels_from_logits(output)\n",
        "      output = output.cpu().detach().numpy()\n",
        "      val_label = val_label.cpu().detach().numpy()\n",
        "\n",
        "      final_out.extend(list(output))\n",
        "      final_lab.extend(list(val_label))\n",
        "\n",
        "      del val_input\n",
        "      del val_label\n",
        "      del val_mask\n",
        "      del output\n",
        "      torch.cuda.empty_cache()\n",
        "    except:\n",
        "      print(\"error\") \n",
        "\n",
        "        \n",
        "  return classification_report(final_lab, final_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCTJ-1hjxANJ"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G70WgrSpd51",
        "outputId": "1888b8b9-b642-496e-cebc-0697dea3edca"
      },
      "source": [
        "print(\"classification_report\")\n",
        "print(eval_model(net, test_dataloader))\n",
        "print(\"--------------------------------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classification_report\n",
            "error\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.90      0.69      1185\n",
            "           1       0.56      0.14      0.23       991\n",
            "\n",
            "    accuracy                           0.56      2176\n",
            "   macro avg       0.56      0.52      0.46      2176\n",
            "weighted avg       0.56      0.56      0.48      2176\n",
            "\n",
            "--------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nm-59YbsAbV"
      },
      "source": [
        "torch.save(net.state_dict(), \"/content/drive/My Drive/multi-modal/text_embed_dict.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9bax5_nzVcg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}